///////////////////////////////////////////////////////////////////////////////////
///////////////////////////////////////////////////////////////////////////////////
///////////////////////////////////////////////////////////////////////////////////
///////////////////////////////////////////////////////////////////////////////////
///////////////////////////////////////////////////////////////////////////////////
///////////////////////////////////////////////////////////////////////////////////
///////////////////////////////////////////////////////////////////////////////////
///////////////////////////////////////////////////////////////////////////////////
///////////////////////////////////////////////////////////////////////////////////
///////////////////////////////////////////////////////////////////////////////////
///////////////////////////////////////////////////////////////////////////////////
xxdiff on Oracle Linux 
/opt/xxdiff-5.1/bin/xxdiff 

///////////////////////////////////////////////////////////////////////////////////
On Oracle Linux 
"p4merge" is installed in /opt
To use it: LD_LIBRARY_PATH=/opt/p4v-2023.2.2446649/lib/ 
/opt/p4v-2023.2.2446649/bin/p4merge
///////////////////////////////////////////////////////////////////////////////////
///////////////////////////////////////////////////////////////////////////////////
In command mode, you can use >> to indent a single line. 
4>> will indent the current and next three lines.

If you don't know how many lines in advance (it may be quite large), 
you can use ranges. Go to the first line of the range and enter 
ma to place marker A. Then go to the last line and enter >'a 
to indent from here to marker A. You can do all sorts of 
wonderful things with ranges.

How they're indented depends on a couple of things like 
your shiftwidth settings. I always have my shiftwidth and tabstop settings the same to avoid problems:

:set ts=4 sw=4

///////////////////////////////////////////////////////////////////////////////////
Print file up to some pattern: deletes line to end

perl -ne'if (/PATTERN/) { close ARGV } else { print }'
///////////////////////////////////////////////////////////////////////////////////
LS_COLORS:
First, generate a local copy of your color settings:

$ dircolors --print-database > ~/.dircolors
Edit your local list as desired. When you're happy with your choices, save the file. Your color settings are just a database and can't be used directly by ls, but you can use dircolors to get shellcode you can use to set LS_COLORS:

$ dircolors --bourne-shell ~/.dircolors 
LS_COLORS='rs=0:di=01;34:ln=01;36:mh=00:
pi=40;33:so=01;35:do=01;35:bd=40;33;01:
cd=40;33;01:or=40;31;01:mi=00:su=37;41:
sg=30;43:ca=30;41:tw=30;42:ow=34;
[...]
export LS_COLORS

Look at 
nvim ~/.dircolors 

and edit and then
$ dircolors --bourne-shell ~/.dircolors >> .bashrc; source .bashrc; ls -F

///////////////////////////////////////////////////////////////////////////////////
You have no doubt by now discovered the --color-auto option that enables this. To change which colors are used, change the definition of LS_COLORS. Use the command dircolors for this.

    Output the default database into a temp file
    Edit the temp file to change the color (bold, underline, background, and foreground colors).
    Have dircolors read in the modified temp file and output the commands to set LS_COLORS and export it. Use eval `...` to capture and evaluate those two commands.

    $ dircolors --print-database > temp 
    $ vi temp 
    $ eval `dircolors -b temp` 
///////////////////////////////////////////////////////////////////////////////////
alias ldots='ls -a | egrep "^\."'    # list dots files and dirs
///////////////////////////////////////////////////////////////////////////////////
$ string="hello-world"
$ prefix="hell"
$ suffix="ld"

$ #remove "hell" from "hello-world" if "hell" is found at the beginning.
$ prefix_removed_string=${string/#$prefix}

$ #remove "ld" from "o-world" if "ld" is found at the end.
$ suffix_removed_String=${prefix_removed_string/%$suffix}
$ echo $suffix_removed_String
o-wor
///////////////////////////////////////////////////////////////////////////////////
Backspace key:
You can check what control characters the system uses with the stty command.
The -a flag will give a human-readable output of the control characters.

stty -a
Look for the "erase" character. If it says "^H," then it uses the older 
Backspace character. Fortunately, you can also fix this with the stty command.
You can set the erase character to the one your computer uses with this simple command:

stty erase '^?'

///////////////////////////////////////////////////////////////////////////////////
Create keyboard shortcuts Cnrl +F{1-4}
Now you have everything you need to create a keyboard shortcut for an activity.
1. Go to System Settings --> Common Appearance and Behavior --> Common Appearance and Behavio  Shortcuts and Gestures --> Custom Shortcuts.
2. Click on Edit --> New --> Global Shortcut --> D-Bus Command.
3. Enter a name for the shortcut. In the Trigger tab, click on the button that says None and press the shortcut you want to use (e.g. Meta+F1).
///////////////////////////////////////////////////////////////////////////////////
Log result of health lsp in nvim:
 m /home/ntausnev/.local/state/nvim/lsp.log
///////////////////////////////////////////////////////////////////////////////////
Neovim on Discover:
/home/ntausnev/bin/nvim  -c "set guicursor= " -c "autocmd OptionSet guicursor noautocmd set guicursor=" z_python.py

/discover/nobackup/ntausnev/nvim.appimage -u \
/discover/nobackup/ntausnev/avim83/.config/astronvim/entry.lua -c \
"set guicursor= | autocmd OptionSet guicursor noautocmd set guicursor=" ~/z_python.py


///////////////////////////////////////////////////////////////////////////////////
Astrovim:
Uninstall:
rm -rf ~/.config/nvim
rm -rf ~/.local/share/nvim 
rm -rf ~/.local/state/nvim 
rm -rf ~/.cache/nvim

git clone https://github.com/AstroNvim/AstroNvim ~/.config/nvim
/home/ntausnev/bin/nvim  -c "set guicursor= " \
 -c "autocmd OptionSet guicursor noautocmd set guicursor=" 


### INSTALL AstroNVim   ###
/discover/nobackup/ntausnev/nvim.appimage -c "set guicursor= | autocmd OptionSet guicursor noautocmd set guicursor=" --headless -c 'autocmd User PackerComplete quitall' -c 'PackerSync'

### Start AstroNVim   ###
/discover/nobackup/ntausnev/nvim.appimage -c "set guicursor= | autocmd OptionSet guicursor noautocmd set guicursor=" 

///////////////////////////////////////////////////////////////////////////////
///////////////////////////////////////////////////////////////////////////////////
///////////////////////////////////////////////////////////////////////////////////

UNINSTALL lunarvim:
bash ~/.local/share/lunarvim/lvim/utils/installer/uninstall.sh
rm -rf /gpfsm/dhome/ntausnev/.cache/lvim*

///////////////////////////////////////////////////////////////////////////////////
Nvim shows weird symbols ( q) when changing modes
This is a bug in your terminal emulator. It happens because Nvim sends 
cursor-shape termcodes by default, if the terminal appears to be 
xterm-compatible (TERM=xterm-256color).

To workaround the issue, you can:

    Use a different terminal emulator
    Disable guicursor in your Nvim config:

    :set guicursor=
    " Workaround some broken plugins which set guicursor indiscriminately.
    :autocmd OptionSet guicursor noautocmd set guicursor=

///////////////////////////////////////////////////////////////////////////////////
Install node:
wget https://nodejs.org/dist/v14.15.4/node-v14.15.4-linux-x64.tar.xz
tar xvf node-v14.15.4-linux-x64.tar.xz --directory=$HOME/tools
cd $HOME/tools/node-v14.15.4-linux-x64/
node -v
Check path for node in ~/bashrc

///////////////////////////////////////////////////////////////////////////////////
Install cargo and rust
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh

after warning
cd /tmp/ find file rustup-init

and copy rustup-init
cp rustup-init /home/ntausnev/tools/.
./rustup-init
source "$HOME/.cargo/env"

export RUSTUP_HOME="/discover/nobackup/ntausnev/RUSTUP_HOME"; export CARGO_HOME="/discover/nobackup/ntausnev/CARGO_HOME"; bash rustup-init.sh


///////////////////////////////////////////////////////////////////
installation tree:

wget https://mama.indstate.edu/users/ice/tree/src/tree-2.1.0.tgz
tar -zxvf tree-2.1.0.tgz
cd tree-2.1.0
make
make PREFIX=/home/ntausnev MANDIR=/home/ntausnev/bin/share/man install

///////////////////////////////////////////////////////////////////////////////////
 SET REGION/X=180W:180E/Y=20S:20N/
 LET sst = IF (tos LT 1000.) THEN  tos*1000.
 fill/palette=blue_red_centered/levels=vc tos[l=2005,d=2] - sst[l=1765,d=1]
///////////////////////////////////////////////////////////////////////////////////
Convert  HadISST.2.2.0.0_sea_ice_concentration.nc   HadISST sea ice concentration
on grid 0.5E - 359E and  89.5N---> 89.S
to grid : -179.5E ---> 179.5E    -89.5N ----> 89.5N

cdo invertlat HadISST.2.2.0.0_sea_ice_concentration.nc z1.nc
ncks -O --msa -d longitude,180.,360. -d longitude,0.,180.0 z1.nc z2.nc
ncap2 -O -s 'where(longitude > 180) longitude=longitude-360' z2.nc sic_v22.nc

Convert from Kelvin to Celcuiuis
ncap2 -O -s 'where(tos>-500.0) tos=tos-273.15' sst_v23.nc sst_v23_Celc.nc

ncap2 -O -s 'where(sst == -1000.) sst=-1.8' z1_tmp.nc z0_tmp.nc



HadISST.2.2.0.0_sea_ice_concentration.nc
///////////////////////////////////////////////////////////////////////////////////
How can I reverse the order of the latitudes from N-S to S-N?
(Notice: NOT the other way round)
cdo invertlat infile outfile

Converting longitude in NetCDF from 0:360 to -180:180 using nco
ncks -O --msa -d lon,181.,360. -d lon,0.,180.0 in.nc out.nc
ncap2 -O -s 'where(lon > 180) lon=lon-360' out.nc out.nc

The first command shifts the data, the second command recalibrates
the coordinate to the newly shifted data. One comment on applying
this algorithm: Be careful to specify hemispheres that
do not overlap, e.g., by inadvertently specifying coordinate
ranges in the first command that both include the date line.
Some users will find using index-based rather than coordinate-based
hyperslabs makes this clearer. Examine a plot of the field to
make sure your rotation was correct.

Would you mind clarifying further the -d lon,181.,360. part? Why 181

Any longitude between 180.0 and the next longitude will do.
This prevents grabbing 180.0 twice, or accidentally skipping a longitude.

///////////////////////////////////////////////////////////////////////////////////
Convert Longitude 0-360 to -180 to 180 or 180W-180E in fortran transform lat lon coordinates
Variables in explanation
long1 is the longitude varying from -180 to 180 or 180W-180E
long3 is the longitude variable from 0 to 360 (all positive)

To convert longitude from (0-360) to (-180 to 180)
Fortran
long1=modulo((long3+180),360)-180

To convert longitude from (-180 to 180) to (0-360)
Fortran
lon3=modulo(lon1,360)

///////////////////////////////////////////////////////////////////////////////////
module show panoply/4.9.3

nf-config --all
to see include path, link path, link libs
///////////////////////////////////////////////////////////////////////////////////
NETCDF4 on discover

module load comp/intel/2021.4.0  netcdf4/4.8.1-serial

After this run the executable:    nf-config --all
to see include path, link path, link libs

 ifort -I/usr/local/other/netcdf4/4.8.1/intel/2021.4.0/include  source1.f90 . . .  -L/usr/local/other/netcdf4/4.8.1/intel/2021.4.0/lib -lnetcdff -lnetcdf -lm -lhdf5_hl -lhdf5 -lsz -lz -lcurl -lrt -ldl -lm

///////////////////////////////////////////////////////////////////////////////////
Ferret on discover:
module load ferret/7.6.0
/usr/local/other/ferret/Ferret-7.6.0-RHEL7/bin/ferret

use /archive/u/ntausnev/HadISST_1_1_GCM/SST_2x2H/sst_2x2H_2021.nc

fill/nolabels/palette=ocean_temp sst[L=8]

///////////////////////////////////////////////////////////////////////////////////
-->  konsole --version
Qt: 4.8.7
KDE Development Platform: 4.14.8
Konsole: 2.10.5

abakan: /home/ntausnev/Python/ECCO_NINO 1000 15:12:22 Sep/26

-->  plasma-desktop --version
Qt: 4.8.7
KDE Development Platform: 4.14.8
Plasma Desktop Shell: 4.11.19

abakan: /home/ntausnev/Python/ECCO_NINO 999 15:13:14 Sep/26

///////////////////////////////////////////////////////////////////////////////////
How to see the version of Oracle Linux
cat /etc/oracle-release

Oracle Linux Server release 7.9

///////////////////////////////////////////////////////////////////////////////////
Replace characters im columns for range lines

To search for the string "abc" starting at column 75 and rep;ace to xyz :
 s/\(^.\{74\}\)abc/\1xyz/

Columns 3 im lines 287-291 replace " " to #
 :287,291s/\(^.\{2\}\) /\1#/



///////////////////////////////////////////////////////////////////////////////////
You should set both to be the editor of choice:

$ export EDITOR=vim
$ export VISUAL=vim
Then the command crontab -e will open in vim.
///////////////////////////////////////////////////////////////////////////////////
Convert snake_case to CamelCase in Vim

You can convert CamelCase to snake_case with this function:
function snakecase
    perl -pe 's#([A-Z])#_\L$1#g' | perl -pe 's#^_##'
end
snake_case to convert CamelCase
camelcase() {
    perl -pe 's#(_|^)(.)#\u$2#g'
}
These functions are useful themselves. Furthermore, you can use them in Vim.
Select snake_case lines to be converted, then type
!camelcase then press return key.

Alternatively:
command -range CamelCase <line1>,<line2>s/\(_\)\(.\)/\u\2/g
///////////////////////////////////////////////////////////////////////////////////
ssh -Y discover-opa
xalloc -N 1 --time=11:00:00 -qos={debug,giss} --constraint=sky

module load comp/intel/19.1.3.304 mpi/impi/19.1.3.304


///////////////////////////////////////////////////////////////////////////////////
we have the ripgrep command-line tool. Ripgrep is a cross-platform utility for
searching regex patterns. It faster than all of the earlier-mentioned search
tools and recursively searches directories for matching patterns.
In terms of speed and performance, no other tool stands out that Ripgrep.

$ sudo dnf install ripgrep      [On CentOS/RHEL/Fedora]  # rg alias
///////////////////////////////////////////////////////////////////////////////////

List the contents of a tar archive
tar tvf my-archive.tar

How can I extract a single file from tar to a different directory?
tar xvf test.tar -C anotherDirectory/ testfile1

tar xvf /archive/u/ntausnev/Eh200_b21/00ACC/accEh200_b21_6280-6289.tar  \
-C /discover/nobackup/ntausnev/Z_Deleted_Files accEh200_b21_6280-6289/OCT6289.accEh200_b21.nc.gz

///////////////////////////////////////////////////////////////////////////////////
Arm forge for modelE:
On discover window get an interactive slurm session:
# OLD ! xalloc -A s1001 -t 11:00:00 -N 1 --ntasks-per-node=28 --qos=giss
/usr/slurm/bin/salloc -A s1001   -t 11:00:00  -n 28   --qos=giss   --constraint="sky|hasw"
source /usr/share/modules/init/ksh
. ./.profile

FOR MPI backtrace:
module purge
module use -a /discover/swdev/gmao_SIteam/modulefiles-SLES12
module load comp/intel/19.1.2.254  mpi/impi/19.1.2.254  mpi/impi-prov/19.1.2.254

module load arm-forge/20.1.0
PATH=.:$PATH
export runId=Eh_x ;   make -j6 setup-run RUN=$runId  MPI=YES  ESMF=NO NPES=24 2>&1 | tee z_setup_${runId}

export runId=Eh_m082615;
make -j6 setup-run RUN=$runId  EXTRA_FFLAGS="-g -O0 -traceback -V"  \
       MPI=YES  ESMF=NO NPES=24 2>&1 | tee z_setup_${runId}

grid ${runId}
${runId}ln

ddt --connect  mpirun -n 4 ./${runId}.exe -i ./I
ddt --connect  mpirun -n 4 ./${runId}.exe cold-restart -i ./I  ## Did not check !!!

On Local macine:


///////////////////////////////////////////////////////////////////////////////////
 bpytop   Monitor System Resources With Bashtop And Bpytop In Linux

///////////////////////////////////////////////////////////////////////////////////
/usr/slurm/bin/salloc -A s1001 -t 11:00:00 -n 28 --qos=giss
///////////////////////////////////////////////////////////////////////////////////
command to print the absolute path of whichever file I feed it
realpath example.txt
///////////////////////////////////////////////////////////////////////////////////
W10 start chrome with Symantec:
cmd
cd C:\Program Files (x86)\Google\Chrome\Application
chrome.exe -no-sandbox
///////////////////////////////////////////////////////////////////////////////////
if you are halfway through typing a command but change your mind,
hit alt-# to add a # at the beginning and enter it as a comment
(or use ctrl-a, #, enter). You can then return to it later via command history.]

///////////////////////////////////////////////////////////////////////////////////
In Bash scripts, subshells (written with parentheses) are convenient ways
to group commands. A common example is to temporarily move to a
different working directory, e.g.
      # do something in current dir
      (cd /some/other/dir && other-command)
      # continue in original dir
///////////////////////////////////////////////////////////////////////////////////
It can be useful to make a few optimizations to your ssh configuration;
for example, this ~/.ssh/config contains settings to avoid dropped connections
in certain network environments, uses compression (which is helpful with
scp over low-bandwidth connections), and multiplex channels to the same
server with a local control file:

      TCPKeepAlive=yes
      ServerAliveInterval=15
      ServerAliveCountMax=6
      Compression=yes
      ControlMaster auto
      ControlPath /tmp/%r@%h:%p
      ControlPersist yes]
///////////////////////////////////////////////////////////////////////////////////
Use screen or tmux to multiplex the screen, especially useful on remote
ssh sessions and to detach and re-attach to a session. byobu can enhance screen
or tmux by providing more information and easier management. A more minimal
alternative for session persistence only is dtach.
///////////////////////////////////////////////////////////////////////////////////
///////////////////////////////////////////////////////////////////////////////////
///////////////////////////////////////////////////////////////////////////////////
///////////////////////////////////////////////////////////////////////////////////
Reuse the last item from the previous command with !$
Reuse the previous command in present command with !!

///////////////////////////////////////////////////////////////////////////////////
The -mtime predicate takes an argument to specify the time frame for the search.
The 90 stands for 90 days. By using a plus sign on the number (+90)
we indicate that weâ€™re looking for a file modified more than 90 days ago.
Write -90 (using a minus sign) for less than 90 days.
Use neither a plus nor a minus to mean exactly 90 days.

Find and delete files older 2 days that has in name "*.slurm.[eo]*":
find . -type f  -mtime +2 -name "*.slurm.[eo]*" -exec \rm -f {} \;

Find and delete files NEW ! 2 days that has in name "*.slurm.[eo]*":
find . -type f  -mtime -2 -name "*.slurm.[eo]*" -exec \rm -f {} \;

Save the deleted files to a log file older than 5 days
find /home/a -mtime +5 -exec ls -l {} \; > mylogfile.log

You have MP3 audio files scattered all over your filesystem.
You like to move them all into a single location.
The find utility can locate all of those files and then execute a command
to move them where you want. For example:

find . -name '*.mp3' -print -exec mv '{}' ~/songs \;

Sort results from find by time:
 ls -la -rt `find . -type f -name *_paths`


///////////////////////////////////////////////////////////////////////////////////
20#March#2020      03.28.20 - 14:31
///////////////////////////////////////////////////////////////////////////////////
nohup  do_dali4.ksh > z_do_dali4.ksh_log 2>&1 </dev/null &
nohup  do_dali5.ksh > z_do_dali5.ksh_log 2>&1 </dev/null &

nohup extract_var_from_accMON.ksh > z_extract_var_from_accMON.ksh_log 2> z_extract_var_from_accMON.ksh_err &
ls -l /proc/9564/fd/


////////////////////////////////////////////////////////////////////////////////////
Release sles
lsb_release -a
lsb_release -a  | grep Description | awk '{ print $6  }'
////////////////////////////////////////////////////////////////////////////////////

https://id.nasa.gov/uss/ChangeDesktopPassword.uss
NDC:Your Desktop password has been changed.
This password will expire on 09/30/2019 and cannot be changed again for 24 hours.

Your Launchpad password is not your desktop log-in password.
You use your Agency User ID and Launchpad password to log in
to NASA applications like SATERN, Secure WebEx, iView, IdMAX, Jabber,
and others.
https://id.nasa.gov/uss/
Your Launchpad password has been changed.
This password will expire on 09/30/2019 and cannot be changed again for 24 hours.

Should you wish, you may change your NCCS LDAP
password at the following URL:
https://www.nccs.nasa.gov/LDAP_pwchange_Gateway.php


////////////////////////////////////////////////////////////////////////////////////
List PRT files that age more 600 minutes
find .   -type f  -mmin +600  -name "*.PRT_[1-9]*"  -print
Delete or remove PRT files modelE
find . -type f -name '*.PRT_[1-9]*' -exec rm {} \;

find . -type f -name '*.slurm.e[1-9]*' -exec rm {} \;
find . -type f -name '*.slurm.o[1-9]*' -exec rm {} \;
////////////////////////////////////////////////////////////////////////////////////
Increase time out ssh:
ssh -XYC -o ServerAliveInterval=120 ntausnev@login.nccs.nasa.gov
////////////////////////////////////////////////////////////////////////////////////
zero hard disk:
 sudo dd if=/dev/zero of=/dev/sdX bs=1024k conv=sync
////////////////////////////////////////////////////////////////////////////////////
Man pages linux:
man -t ksh | ps2pdf - ksh.pdf
man -t ksh > ksh.ps

////////////////////////////////////////////////////////////////////////////////////
How to replace some values of a  netcdf variable?
ncap2 -s 'Time(:)={4155, 4165, 4175, 4185, 4195, 4205, 4215, 4225, 4235}' EUC.E200F40oQ40.nc z.nc

////////////////////////////////////////////////////////////////////////////////////
Latitude(lat), longitude(lon) and levels (lev) are coordinate variables
(dimensions) containing the grid information.
CDO is designed to handle data variables. Plain dimensions are some kind of
meta information of data variables and hence handled automatically.

For renaming and changing the dimension attributes, use the NCOs instead.
Examples:
Rename LATS and LONS to lat and lon
ncrename -v LATS,lat -v LONS,lon infile outfile

Change the attributes of lat and lon
ncatted -a units,lat,o,c,"degrees_north" -a units,lon,o,c,"degrees_east" infile outfile

Change type of calendar time axis:
ncatted -a calendar,time,o,c,"noleap" z_months1.nc z_months_365.nc


Deleting and adding attributes and variables with NCO
Posted in and tagged netcdf , nco on May 14, 2018

Here are some more common tasks I have come across when needing to edit
netCDF files. This is usually when they need to be ingested into different models
or post-processing scripts that require the netCDF files to be in a certain format.

Deleting a global attribute
You want to delete a single global attribute from a netCDF file.

This can be done using ncatted, e.g.:

ncatted -a global_attr_name,d,, infile.nc outfile.nc
This command takes for arguments separated by commas. Since we are specifying
deletion, (d), only the first two arguments are needed, but the remaining
commas bust be typed in.

Convert a variable type
A variable is of incorrect type and you need to change it.
You can use ncap2 (nc arithmetic processing).

ncap2 -s 'time=float(time)'
Assumes you already have the variable defined. The -s option specifies
that we are providing an inline script, within the quote marks.

Add a variable mapped over a certain dimension
You want to a variable that iterates over a given dimension, such as time.
The variable should increase montonically (i.e. increase by n each time
until the end of the dimension length is reached. I often find I need
to do this after having merged netCDF files that were single
time slices from a model output or satellite data or otherwise. ncap2 is used.

ncap2 -s 'time[$time]=array(54760,30,$time)' infile.nc outfile.nc
We are assigning the current time variable (assuming we have already
added this) an array of values, specified by the (start_point, step,
dimension). In this case, we get an array of values starting at 54760,
 increasing by 30 each point, as long as the time dimension.
The -s option simply means we are giving an inline script as
the input to the ncap2 program.

Add an attribute one at a time
You want to an attribute to a variable. (I.e. metadata attributes
for variables, such as units, etc.). We can use ncatted for this.
 (netCDF attribute editor).

ncatted -a attribute,variable,a,c,"Atrribute Value" infile.nc
The -a option specifies append mode, and so we only need to supply
the input file infile.nc. The value of the attribute is given
in the quotation marks. The nco documentation suggested also putting
single quotation marks around the comma-separated arguments as well,
but I found this produced unexpected results where the double quotes
 were escaped and inserted into the actual attribute value as well.
Could possibly be a unix thing though.

Extract variable SST from in.nc from in
$ ncks -v SST in.nc out.NCCS

Delete variable
$ ncwa -a lev in.nc out.nc
Repeack the out.nc after averaging-out the level dimension with )€œlev)
$ ncks -C -O -x -v lev in.nc out.nc
Delete dimension
$ ncwa -a lev in.nc out.nc

This works pretty well, if you want to print just the values of
var1 and var2 from netCDF file foo.nc:

  ncdump -v var1,var2 foo.nc | sed -e '1,/data:/d' -e '$d'

It eliminates all the header info and the last line that's just "}".
It doesn't work for netCDF-4 files that have nested groups.


//////////////////// FERRET  ///////////////////////////////////////////////////////
Horizontal interpolation
yes? set data 2009-2010_cal.vsurf_g.nc
yes? SHADE/X=160W:40W/Y=20N:70N  VSURF[l=1]

yes? DEFINE AXIS/X=180w:180e:2/UNITS=degrees xecco
yes? DEFINE AXIS/y=90s:90n:2/UNITS=degrees yecco
yes? DEFINE GRID/X=xecco/Y=yecco gecco
yes? SHADE/X=150W:130W/Y=10s:10N  VSURF[l=1,G=GECCO@AVE]
yes? let wind2x2 = VSURF[l=1,G=GECCO@AVE]
yes?  SHADE/X=150W:130W/Y=10s:10N wind2x2
yes? SAVE/FILE=v2x2.nc  wind2x2

Ferret how to list the axis values?
sh data

list x[g=Variable]  ! <======== (return the x axis of variable Variable)

define axis/x=180W:180E:1/units=degrees x1

Redefine values time axis:
define axis/t=4150:4390:10/units=years `POT_TEMP,return=taxis`

list /i=1:3 x[g=sst]  ! <======== (return the x axis of sst)
////////////////////////////////////////////////////////////////////////////////////

Edit NETCDF file:

  ncdump ANNt1850-2014.T.E200f10a-eF40oQ40_cdo.nc > z.cdl
  vi z.cdl
  ncgen -b z.cdl -o newsmoke.nc

////////////////////////////////////////////////////////////////////////////////////
To concatenate files, use ncecat:

ncecat *nc -O merged.nc

This will merge all the netcdf files in a folder, creating a new record dimension
if one does not exist. The record dimension is often the time dimension,
for example if you have a set of netCDF files, with each one representing
some spatial field at a given timestep. If appropriate, you can
rename this record dimension to something more useful using the ncrename utility
(another utility in the NCO package).
Renaming dimensions

ncrename -d record,time merged.nc

The -d flag specifies that we are going to rename the dimension in the netcdf file.,
from "record"  to "time".
list=$(ls *T.E200f10a-eF40oQ40.nc)
ncecat $list -O ANNt1850-2014.T.E200f10a-eF40oQ40.nc
ncrename -d record,time  ANNt1850-2014.T.E200f10a-eF40oQ40.nc

 There are also flags to rename other attributes, see the ncrename manual page

////////////////////////////////////////////////////////////////////////////////////
Change the reference time units or add a missing time dimension

Use the settaxis operator to do this for you, e.g. set the reference time units to "2000-01-01,12:00:00,1day":

cdo -r -f nc -settaxis,2000-01-01,12:00:00,1day infile outfile

////////////////////////////////////////////////////////////////////////////////////
 Compute field mean value

Use ncwa (weighted average)

ncwa -a lon lat input.nc output.nc

will compute the spatial mean (based on variables lon and lat).

If a mask (land-sea for example) has to be specified:

ncwa -a x,y -B 'error_field>=0' input.nc output.nc

where the argument after -B is the condition for a point to be considered in the average.
Add a time record

ncecat -O -u time in1.nc out1.nc

If you execute

ncdump out1.nc

you will see the line

time = UNLIMITED ; // (1 currently)

Add a time variable

ncap2 -O -s 'time=10' out1.nc out1.nc

    -O stands for overwrite
    -s stands for script and means the command is used with in-line script.

Concatenate files

ncrcat out[1-3].nc out123.nc

Modification of the attributes

Use ncatted (attributed editor)
Modify values of an attribute

ncatted -a missing_value,TSM,m,d,-999 northsea_TSM.nc

replaces the attribute missing_value of the variable TSM by -999 in the file northsea_TSM.nc
Add a missing_value attribute to a file

This example is particularly useful when one wants to set the _FillValue to -99 (or -999, ...) in a NetCDF file generated by Diva.

ncatted -a _FillValue,analyzed_field,c,f,-99 results.nc

The benefit is that ncview automatically detect the missing value and does not plot it.
////////////////////////////////////////////////////////////////////////////////////


NETCDF-4 on discover:
discover31: /usr/local/other/SLES11/netcdf4/4.1.3   1634   15:39:02  Oct/30

     intel-11.1.038/  intel-12.1.0.233/

////////////////////////////////////////////////////////////////////////////////////
Ferret  print hard copy from interactive go
yes? use EUC.E200F40oQ40.nc
yes? PLOT/X=140.00E:80.00W/J=0/K=0/T=1850.00:2014.00 TRANSP[d=1,T=@AVE]
yes? PPL CLSPLT
yes? SPAWN Fprint -o TNL_name.ps -l cps -R metafile.plt &
exit
/usr/bin/ps2pdf TNL_name.ps TNL_name.pdf


////////////////////////////////////////////////////////////////////////////////////
CLliMAF library collaborative development of climate model outputs assessment
https://media.readthedocs.org/pdf/climaf/stable/climaf.pdf
////////////////////////////////////////////////////////////////////////////////////
Look month hourly data for hycom
ls -la -rt runosi* | grep "s1001 [6-7]"
////////////////////////////////////////////////////////////////////////////////////
CDO on discover:
This module writes information about the structure and contents of all input
files to standard output.

cdo -C no infon z_avg_month.nc
    -1 :       Date     Time   Level Gridsize    Miss :     Minimum        Mean     Maximum : Parameter name
     1 : 1915-01-16 12:00:00       0    12960    3605 :    -0.10421 -0.00027793   0.0052758 : asalflx
     2 : 1915-02-14 21:00:00       0    12960    3605 :    -0.12076  1.1421e-05   0.0052884 : asalflx

cdo griddes infile.nc     --> Prints the description of all grids

Get information about netcdf file:
 cdo -s sinfo b_map_1990-2019_01.nc | m

Get from hourly data to day or monthly data:
cdo daymean asalflx_262801-315360.nc z_mean_days.nc
cdo monmean asalflx_262801-315360.nc z_avg_month.nc

 for selecting period from timestep 21-70:
cdo seltimestep,21/70 input_file.nc output_file.nc
Get year 1996-1998 and 2000:
cdo selyear,1996/1998,2000 tar.NCEP.R2.1996.2005.nc tar.1996a1998.2000.nc
////////////////////////////////////////////////////////////////////////////////////
Set syntax for *.F90 files
:set syntax=fortran
////////////////////////////////////////////////////////////////////////////////////
We can use different key mappings for easy navigation between splits to save
a keystroke. So instead of ctrl-w then j
simple ctrl-j:

nnoremap <C-J> <C-W><C-J>
nnoremap <C-K> <C-W><C-K>
nnoremap <C-L> <C-W><C-L>
nnoremap <C-H> <C-W><C-H>
///////////////////////////////////////////////////////////////////////////////////
////////////////////////////////////////////////////////////////////////////////////
Allinea on Discover 08.14.18 - 12:12:
/usr/bin/ssh -XYqt -p2255 `hostname` '. /etc/profile;/usr/slurm/bin/salloc \
  --nodes=1 -t 12:0:00 --constraint=hasw --qos=giss'

wait borg... prompt

source /usr/share/modules/init/ksh
. ./.profile

export runId=Eh_m082615;
make -j6 setup-run RUN=$runId  EXTRA_FFLAGS="-g -O0 -traceback -V"  \
       MPI=YES  ESMF=NO NPES=24 2>&1 | tee z_setup_${runId}

grid ${runId}
${runId}ln

THE FIRST
ddt --processes=1 ./{runId} -i ./I -cold-restart

to continue:
ddt --processes=1 ./{runId} -i ./I

////////////////////////////////////////////////////////////////////////////////////
github: ntausnev Abakan#1963

git clone git://github.com/ntausnev/MySysDir.git z_git

Push to remote repository:
git remote rm origin
git remote add origin git@github.com:ntausnev/MySysDir.git
git push origin master

////////////////////////////////////////////////////////////////////////////////////
Key shortcuts for ctags:
,tt  show tag bar

You can also place your cursor on some text and press ^] to jump to that tag.

^]  Jump to definition
^t  Jump back from definition
^W }  Preview definition
g] See all definitions

,tt

////////////////////////////////////////////////////////////////////////////////////
import pdb; pdb.set_trace()  # XXX BREAKPOINT

////////////////////////////////////////////////////////////////////////////////////
Disk space used by directory:

  du -sh dirName
////////////////////////////////////////////////////////////////////////////////////
Indenting using markers

  ma     Mark top of block to indent as marker 'a'
  ...move cursor to end location

  >'a    Indent from marker 'a' to current location
////////////////////////////////////////////////////////////////////////////////////
NCO operator ncea on discover
/usr/local/other/SLES11.1/nco/4.4.4/intel-12.1.0.233/bin/ncea
////////////////////////////////////////////////////////////////////////////////////
Ip adress angara: ntausnev@gs611-angara.giss.nasa.gov is 128.183.2.174
////////////////////////////////////////////////////////////////////////////////////
creating a new GRUB config file
  $su
  # cd /boot/grub2
  # mv grub.cfg grub.cfg.old
  # grub2-mkconfig -o grub.cfg
  # rebooting
////////////////////////////////////////////////////////////////////////////////////
NETCDF  compiling:
 ifort -v -i4 -r8 -nowarn -convert big_endian -save-temps -g -O0 -check  \
     -check noarg_temp_created -check nopointer -warn -warn noerrors \
     -fpe0 -traceback -ftrapuv \
     -I/usr/local/other/netcdf/3.6.2_intel-12.0.1.107/include \
      cdf_rb_mod.f90 test_cdf_rb_mod.f90 \
      -L/usr/local/other/netcdf/3.6.2_intel-12.0.1.107/lib -lnetcdf; a.out
////////////////////////////////////////////////////////////////////////////////////
all double blank lines should be deleted completely,
but single blank lines should be kept.
cat -s fileName
////////////////////////////////////////////////////////////////////////////////////
How do I bring dnf packages synced between 2 Fedora's?
You can list all the installed packages using rpm:
  rpm -qa > list.txt
Installing packages can be worked around like this:
    dnf install $(cat list.txt)
////////////////////////////////////////////////////////////////////////////////////
How to Replace All Occurrences of a Word
in All Files in Linux Command Line

find <path_to_directory> -type f -exec sed -i 's/<search_text>/<replace_text>/g' {} \;

////////////////////////////////////////////////////////////////////////////////////
 Option for ifort -assume buffered_io MPI output in order
 -assume buffered_stdout.
////////////////////////////////////////////////////////////////////////////////////
# vim:set sr et ts=4 sw=4 ft=python fenc=utf-8: // See Vim, :help 'modeline'
////////////////////////////////////////////////////////////////////////////////////
Zero disk on fedora
dd if=/dev/zero of=/dev/sdb obs=1M

////////////////////////////////////////////////////////////////////////////////////
Testing hard drives
First run a "short" test:
smartctl -t short /dev/sdX
Look at the result:
smartctl -a /dev/sdX
Next run a "long" test:
smartctl -t long /dev/sdX
and look at the result.  Should say "Passed", and no serious errors shown in the numerical table.

////////////////////////////////////////////////////////////////////////////////////
Upgrade fedora:


1. Install the DNF plugin
sudo dnf upgrade --refresh
sudo dnf install dnf-plugin-system-upgrade

2. Start the update with DNF
Now that your system is up-to-date, backed up, and you have the DNF plugin installed,
you can begin the upgrade by using the following command in a terminal:

sudo dnf system-upgrade download --releasever=27 [ --allowerasing ]

This command will begin downloading all of the upgrades for your machine locally
to prepare for the upgrade. If you have issues when upgrading because of
\packages without updates, broken dependencies, or retired packages,
add the --allowerasing flag when typing the above command.
This will allow DNF to remove packages that may be blocking your
system upgrade.

3. Reboot and upgrade

Once the previous command finishes downloading all of the upgrades,
your system will be ready for rebooting. To boot your system into the upgrade
process, type the following command in a terminal:
sudo dnf system-upgrade reboot

Your system will restart after this. Many releases ago, the fedup tool
would create a new option on the kernel selection / boot screen.
With the dnf-plugin-system-upgrade package, your system reboots
into the current kernel installed for Fedora 26;
this is normal. Shortly after the kernel selection screen,
your system begins the upgrade process.

4. Resolving upgrade problems

On occasion, there may be unexpected issues when you upgrade your system.
If you experience any issues, please visit the DNF system upgrade wiki
https://fedoraproject.org/wiki/DNF_system_upgrade#Resolving_post-upgrade_issues
page for more information on troubleshooting in the event of a problem.

If you are having issues upgrading and have third-party repositories
installed on your system, you may need to disable these repositories
while you are upgrading. For support with repositories not provided by Fedora,
please contact the providers of the repositories.

dnf install dnf-plugin-system-upgrade &&
 dnf system-upgrade download --refresh --releasever=27 &&
 dnf system-upgrade reboot
////////////////////////////////////////////////////////////////////////////////////
Set the first character FORTRAN carriage-control
-ccdefault fortran
////////////////////////////////////////////////////////////////////////////////////
How to make a Fedora USB stick
if you in linux just simple
1. download iso
2. backup file on usb drive
3. open terminal
4. write command dd if=/folder-location/name.iso of=/dev/sdXX hit enter
                 dd bs=4M if=ubuntu-12.04.2-server-i386.iso of=/dev/sdb
sudo dd bs=4M if=Downloads/ubuntu-19.04-desktop-amd64.iso of=/dev/sdb conv=fdatasync
5. reboot and boot from usb
////////////////////////////////////////////////////////////////////////////////////
Convert netcdf file to giss format:
write_giss2d  oicefr_MAR2900-2909.Eh193.nc oicefr_MAR2900-2909.Eh193.giss

////////////////////////////////////////////////////////////////////////////////////
How to access a usb flash drive from the terminal?
(How can I mount a flash drive manually?)


Find what the drive is called

You'll need to know what the drive is called to mount it. To do that fire off:

sudo fdisk -l
You're looking for a partition that should look something like:
 /dev/sdb1. Remember what it's called.

2. Create a mount point
Create a new directory in /media so you can mount the drive onto the filesystem:
sudo  mkdir /media/usb

3. Mount!
sudo mount /dev/sdb1 /media/usb

When you're done, just fire off:
sudo umount /media/usb

////////////////////////////////////////////////////////////////////////////////////
On Angara mount disk:
sudo fdisk -l
sudo mount -t vfat -o umask=0,uid=ntausnev,gid=ntausnev /dev/sdb1 ~/external_disks/
cd external_disks/
...
sudo umount /dev/sdb1


////////////////////////////////////////////////////////////////////////////////////
Hard drive testing:
 (sudo)  smartctl -t long /dev/sdb1
 later see results : [sudo] smatrctl -a /dev/sdb1  ==> to view results

////////////////////////////////////////////////////////////////////////////////////
////////////////////////////////////////////////////////////////////////////////////
////////////////////////////////////////////////////////////////////////////////////
How to format a USB flash drive on Fedora:

As SUPERUSER !!!
fdisk -l ===> shows all volumes in your PC
or df
or lsblk

find the usb flash drive ( /dev/sdb )

umount /dev/sdb  ====> unmount the drive
mkfs.vfat -n 'TNL-FLASH' -I /dev/sdb
eject /dev/sdb  ===> eject the device

The fdisk output didn't appear to show the removable media device.
Was it plugged in at the time? A quick and easy way to check
is to run the command with and without the attached device and compare the
output, or watch the kernel output when the device is first attached
Code:
dmesg|tail
Of course, be VERY CAREFUL to specify the correct device.
You can find it with this command right after you plug it in:
Code:
dmesg | tail
Or: lsblk



//////////////////////////////////////////////////////////////////////////////////
Wi-Fi strenth signal:
 iwconfig wlp3s0 | grep -i --color quality

////////////////////////////////////////////////////////////////////////////////////
To see account aging information such as expiry date and time, enter:

chage -l userNameHere
To see account aging info for vivek, enter:
$ chage -l vivek

To disable password aging / expiration for user foo, type command as follows and set:
# chage -I -1 -m 0 -M 99999 -E -1 username

ntausnev@gs611-fedloaner Downloads]$ chage -l ntausnev
Last password change                                    : Apr 03, 2017
Password expires                                        : never
Password inactive                                       : never
Account expires                                         : never
Minimum number of days between password change          : 0
Maximum number of days between password change          : 99999
Number of days of warning before password expires       : 15
[ntausnev@gs611-fedloaner Downloads]$

////////////////////////////////////////////////////////////////////////////////////
I have enabled "Desktop Grid" for Ctrl+F8 but nothing happens when I press Ctrl+F8.
Fixed by switching from OpenGL to XRender in
System Settings -> Hardware -> Display and Monitor -> Compositor.
////////////////////////////////////////////////////////////////////////////////////
To list installed colorschemes:
:colorscheme + space + TAB
////////////////////////////////////////////////////////////////////////////////////
////////////////////////////////////////////////////////////////////////////////////
To copy the whole file/buffer, in vim command mode,
first go to the beginning via gg, then type

"*yG"

how can I write out a specific range of lines to a new file
vim -c "100,200w new_file.txt" -c wq original_file.txt

The most general:
Move cursor to first line of the group you want to write.
Hit m and a sequentiall. That's "set mark named 'a'".

Move cursor to last line of the group, hit 'm' and 'b'.'

Change over to command mode hit: as a sequence do :'a,'b w
filename then hit return.
////////////////////////////////////////////////////////////////////////////////////
Delete files recursively whose name ends in .o as well,
if that's not what you want, use one of these:

find . -type f -name '*.o' -delete
find . -type f -name '*.o' -exec rm {} \;
rm -- **/*.o

NOTE: all TWO options will delete directories whose name ends in .o
as well
find . -name '*.o' -delete
or, for non-GNU find:
find . -name '*.o' -exec rm -r {} \;
////////////////////////////////////////////////////////////////////////////////////
Type the following command at the shell prompt to find out top 10 largest file/directories:
du -hsx * | sort -rh | head -10
////////////////////////////////////////////////////////////////////////////////////
If you lost your wifi interface after upgrade, use this command:
sudo modprobe wl
////////////////////////////////////////////////////////////////////////////////////
Installation drive-google:
Enable the copr repository:

dnf copr enable vaughan/drive-google
Install the package (drive-google):

dnf install drive-google

Guide:
https://github.com/odeke-em/drive#drivehttps://github.com/odeke-em/drive#drive
////////////////////////////////////////////////////////////////////////////////////
ca' changes the quotes as well, not only inside the quotes in vim
cf_ - change up to the first '_' (including);
ct_ - change up to the first '_' (excluding);
cw - change the first word;
Or ct_ to change from the cursor to the next _ character.
3s, "substitute 3 characters" is the same as c3l.  3cl and c3l should be the same,
////////////////////////////////////////////////////////////////////////////////////
watch sensors
////////////////////////////////////////////////////////////////////////////////////
Installing from the RPM:

After downloading the most recent RPM file, install DiffMerge using the following command:

sudo rpm --install diffmerge-4.2.0.*.rpm

This completely installs DiffMerge;
this includes an executable in /usr/bin/diffmerge a man page,
and a menu item in the Fedora Application | Programming menu.

To uninstall, type the following:

sudo rpm --erase diffmerge
////////////////////////////////////////////////////////////////////////////////////
set column 80 light grey
highlight ColorColumn ctermbg=8

set cursorcolumn   # highlight current column
set nocursorcolumn # NO highlight current column
////////////////////////////////////////////////////////////////////////////////////
Konsole :

konsoleprofile colors=Material
konsoleprofile colors=Monokai
konsoleprofile colors=SolarizedLight
konsoleprofile colors=SolarizedDark

////////////////////////////////////////////////////////////////////////////////////
https://github.com/whoozle/konsole-material-color-scheme
Konsole is one of the best terminal emulators in the world.
Here's material color scheme for it.

Usually konsole color schemes are placed inside ~/.local/share/konsole.
Put Material.colorscheme there and set it as active theme:
 Settings --> Edit Current Profile --> Appearance tab --> Material



Thank you for your attention. Have fun.


////////////////////////////////////////////////////////////////////////////////////
PYTHON_COMPAT=( python{2_7,3_{3,4,5}} pypy  )

from __future__ import print_function
print('cats', 'dogs', 'mice', sep=', ')

////////////////////////////////////////////////////////////////////////////////////

Allinea on Discover:
/usr/slurm/bin/salloc -N 1 --time=01:00:00 --constraint=sp3  --qos=debug
/usr/slurm/bin/salloc -N 1 --time=01:00:00 --constraint=hasw --qos=debug

/usr/slurm/bin/salloc -N 1 --time=12:00:00 --constraint=sp3  --qos=giss

/usr/slurm/bin/salloc -A s1001 -t 11:00:00 -n 28 --qos=giss


get borg prompt
module load  tool/allinea-tools-6.0.4
module load  tool/allinea-tools-6.0.4
ddt --connect &
Select IntelMPI and parametrs

////////////////////////////////////////////////////////////////////////////////////
Delete *.ERR files from model directory
find . -name "*.ERR" -type f
find . -name "*.ERR" -type f -delete
////////////////////////////////////////////////////////////////////////////////////
/usr/bin/konsole --new-tab -p tabtitle="TNL tabs name"
////////////////////////////////////////////////////////////////////////////////////

How do I list both programs that came with my distribution
and those I manually installed?
rpm -qa

dnf info texlive-flippdf-svn15878.1.0-12.fc22.noarch

////////////////////////////////////////////////////////////////////////////////////
#!/usr/bin/env python

import matplotlib.pyplot as plt
import numpy as np

x = arange(5)
y = arange(7)
X, Y = meshgrid(x,y)
z = X+Y
c=contour(X, Y, z, [5])
clabel(c, inline=1)
////////////////////////////////////////////////////////////////////////////////////
If you have a gui tool such as kdiff3 on your system, you can see a visual
representation of the differences by using git difftool:

git difftool # it works on fedora

////////////////////////////////////////////////////////////////////////////////////
Look at pdf files on Discover
 evince multipage_pdf.pdf
////////////////////////////////////////////////////////////////////////////////////
print(matplotlib.__version__)     #
print(matplotlib.getbackend())
matplotlib.use("nbagg")
////////////////////////////////////////////////////////////////////////////////////
10.16.15
./Anaconda3-2.3.0-Linux-x86_64.sh # It installs python 3.4 libraries
conda -V
conda update conda
#create environment for python 3.5
conda create -n tnl_py35 python=3.5 anaconda

# To activate this environment, use:
# bash; source activate tnl_py27
# $ source activate tnl_py35
#
# To deactivate this environment, use:
# $ source deactivate
#

#Install additional packages to a virtual environment:
conda install --name tnl_py27 basemap
conda install --name tnl_py27 pil

////////////////////////////////////////////////////////////////////////////////////
////////////////////////////////////////////////////////////////////////////////////
10.07.15
Putty on ACES machine:
start cygwin
init -- -nolock -multiwindow
start putty
////////////////////////////////////////////////////////////////////////////////////
Print Screen on W7
1. Print Screen button
2. Paint program start
3. Cursor on white space
4. CTRL + V
5. Crop ( select ) need to select
6. CTRL + C
7. CTRL + N
8. Select do not save
9. CTRL + V
10. Save with new name

////////////////////////////////////////////////////////////////////////////////////
Fedora: curl pip yapf meld xxdiff compare

dnf install levien-inconsolata-fonts.noarch   <--- Fedora INCONSOLATA Font !
////////////////////////////////////////////////////////////////////////////////////
format python with yapf
Install

pip install --upgrade pip
pip install yapf

Usage
yapf --style ~/pip8.style main.py test.py
yapf --style='{based_on_style: google, indent_width: 4}' file:w

===========================================================
yapf --style ~/pip8.style plot_current_yz_cdf4.py > z2.py
===========================================================

The vim plugin allows you to reformat a range of code.
Place it into the .vim/autoload directory.
You can add key bindings in the .vimrc file:

map <C-Y> :call yapf#YAPF()<cr>
imap <C-Y> <c-o>:call yapf#YAPF()<cr>

    File:
pip8.style

[style]
based_on_style = pep8
spaces_before_comment = 4
split_before_logical_operator = true
////////////////////////////////////////////////////////////////////////////////////
////////////////////////////////////////////////////////////////////////////////////
Update spf13
curl https://j.mp/spf13-vim3 -L -o - | sh
////////////////////////////////////////////////////////////////////////////////////
Setup master branch:

module purge;
. /etc/profile.d/modules.sh
. ./.profile
module purge;
. /etc/profile.d/modules.sh
module load comp/intel-14.0.3.174 mpi/impi-4.1.3.048 other/comp/gcc-4.9.1  \
       other/git-1.8.5.2 tool/allinea-tools-6.0.4
export runId=Eh_m082615
make -j6 setup-run RUN=$runId  MPI=YES  ESMF=NO NPES=24 2>&1 | tee z_setup_${runId}

for totalView:
make -j6 setup-run RUN=$runId  EXTRA_FFLAGS="-g -O0 -traceback -V"  \
       MPI=YES  ESMF=NO NPES=24 2>&1 | tee z_setup_${runId}



////////////////////////////////////////////////////////////////////////////////////
Totalview Allinea on slurm node:
/usr/bin/ssh -XYqt -p2255 `hostname` '. /etc/profile;/usr/slurm/bin/salloc --nodes=1 -t 01:0:00 --constraint=hasw --qos=debug'

/usr/bin/ssh -XYqt -p2255 `hostname` '. /etc/profile;/usr/slurm/bin/salloc \
  --nodes=1 -t 12:0:00 --constraint=hasw --qos=giss'

wait borg... prompt

source /usr/share/modules/init/ksh
. ./.profile
module purge; module load comp/intel-11.1.072 mpi/impi-4.1.0.024 tool/tview-8.9.2.2
PATH=.:$PATH
export runId=Eh_x ;   make -j6 setup-run RUN=$runId  MPI=YES  ESMF=NO NPES=24 2>&1 | tee z_setup_${runId}

export runId=Eh_m082615;
make -j6 setup-run RUN=$runId  EXTRA_FFLAGS="-g -O0 -traceback -V"  \
       MPI=YES  ESMF=NO NPES=24 2>&1 | tee z_setup_${runId}

grid ${runId}
${runId}ln
totalview ./${runId}.exe -a -cold-restart -i ./I
totalview ./${runId}.exe -a -i ./I

////////////////////////////////////////////////////////////////////////////////////
MPI on discover:
mpif90 -r8 -g t_impi.f90

TotalView + MPI on discover
totalview ./a.out
Select parallel Intel MPI hydra
task and nodes
OK.  Look at the source code.

////////////////////////////////////////////////////////////////////////////////////
NCAD Password Change Guidelines and Utility /ACES
https://managemyndc.nasa.gov/

ndc\ntausnev
...

////////////////////////////////////////////////////////////////////////////////////
You use your Agency User ID and "Launchpad" password (sometimes referred to as a "profile"
or "IdMAX" password) to log into NASA applications like SATERN, Secure WebEx, iView,
IdMAX, Jabber, and others.

To change your launchpad password go to
https://id.nasa.gov/uss/PasswordChange.uss
https://id.nasa.gov
https://id.nasa.gov/uss/PasswordChange.uss
go to bottom line
and follow the reset password process.

LDAP(discover)
https://www.nccs.nasa.gov/LDAP_pwchange_Gateway.php
or
passwd

Your "NDC" password must be changed before it expires to ensure
you are not locked out of your computer. The "NDC Desktop" password
is also referred to as your "NCAD Password".
This is NOT your Launchpad or NED Password.
Quick Links: Window
For typical Windows users at NASA, this is the password used to log
in to your Windows desktop or laptop system. If you received a notification
during your Windows desktop login and changed your password at that time,
please disregard this message.

For both Windows and Mac users, this password is used to access NOMAD,
Agency SharePoint and ShuttlePortal.

Windows Users

If you use a smartcard for desktop login:
Press Ctrl+Alt+Delete and click Change a password.

Do NOT update your Smart Card PIN!!
Click Other Credentials, and then select your
NDC Domain account to change your password.

FAQs regarding NASA smartcards are available at http://inside.nasa.gov/ocio/content/nasa-smartcard-faq
If you use a username and password for desktop login:

Press Ctrl+Alt+Delete to open the Windows Security tool.
Click Change a password and complete the required fields.
If you are having problems getting either of the process to work:

You can visit https://id.nasa.gov/uss/DesktopPasswordChangeGuidelines.uss ,
which refers to the Desktop Password, or call the ESD at 1-877-677-2123.


////////////////////////////////////////////////////////////////////////////////////
Convert column to row
\tp
This is currently what i am dealing with:

$cat k
23
22
35
24
42
:
:
36
I have file like this and I want to use vim convert it like this.

22,23,35,24,42,8,......,36

awk -F"\n" '$1=$1' RS="" OFS="," file

awk 'BEGIN { ORS = " "  } { print  }' infile



awk '{print $1}' z_column_2 | awk -F"\n" '$1=$1' RS="" OFS=" "
////////////////////////////////////////////////////////////////////////////////////
awk - how to subtract a constant number from a column
awk '{print ($1 - 1280449530) " " $2}' file
////////////////////////////////////////////////////////////////////////////////////
delete column from file:
file: c1 c2 c3 c4 c5
perl -lane 'splice @F,1,1; print join " ",@F' file  # delete 2 column
perl -lane 'splice @F,2,1; print join " ",@F' file  # delete 3 column

perl -lane 'splice @F,n-1,k; print join " ",@F' file  # delete k columns from n

////////////////////////////////////////////////////////////////////////////////////
Interactive mode

Usage:   sI [-g groupID] [mov|d|p|r][-][s(ky)|h(asw)|c(ascade)]  ncpus[:mem/cpu] [walltime(HH[:MM])]
      mov=datamove d=debug p=giss-priority r=regular -=exclude_node_listed default: debug any_n

/usr/slurm/bin/salloc -A s1001  -t 1:00:00  -n 88   --qos=debug   --constraint="sky|hasw|cas"


#!/bin/ksh
   action=/usr/slurm/bin/salloc

#  maybe alternate accounts depending on userID
   account=$( id -gn )
   nargs=$#

#  defaults
   type='' ; cpus_per_node=16 ; opt='' ; wc_time=1 ; OS=''

#  special partitions: datamove - special services: debug
   if [[ $# -gt 0 ]]
   then if [[ $1 = [mM]* ]]       ; # datamove nodes
        then opt="-p datamove" ; wc_time=1 ; cpus_per_node=4 ; shift
        elif [[ $1 != [0-9]* ]]
        then a=$1 ; shift
             if [[ $a = [dD]* ]]
             then opt="debug" ; a=${a#[dD]}
             fi
             if [[ $a != '' ]] ; # G=g (high/giss priority)
             then type=$a
             fi
        fi
   fi

#  not recommended: giss priority and/or specific node type
   if [[ $type = [gGsh]* && $opt != 'debug' ]]
   then opt="--qos=giss"
   fi
   if [[ $type = *1 ]]
   then cpus_per_node=16 ; type='-C sp1'
   elif [[ $type = [!sShH]*3 ]]
   then  OS='-C sp3' ; type=''
   elif [[ $type = [sS]*3 ]]
   then cpus_per_node=16 ; type='-C sp3 -C sand'
   elif [[ $type = [hH]* ]]
   then cpus_per_node=28 ; type=' -C hasw'
   elif [[ $type = [sS]* ]]
   then cpus_per_node=16 ; type='-C sand'
   else type=''
   fi

# time/CPU/memory requirements
   wc_time=${2:-$wc_time} ; wc_hrs=${wc_time%%:*}
   if [[ $wc_time = $wc_hrs ]] ; then wc_time=${wc_time}:00 ; fi
   ncpus=${1:-$cpus_per_node} ; mem=0 ; MEM=''
   if [[ ncpus = *:* ]]
   then mem=${ncpus#*:} ; ncpus=${ncpus%:*} ; MEM="--mem-per-cpu=${mem}"
   fi
#  special cases for nodes that potentially may be shared
   if [[ ${opt} = "-p datamove" ]]
   then if [[ $# -eq 0 ]]
        then ncpus=1
        elif [[ $1 = [1-3] ]]
        then ncpus=$1
        fi
   fi

   if [[ $type != '' ]]
   then (( nodes = ( ncpus + cpus_per_node - 1 )/cpus_per_node ))
        ncpus=$(( cpus_per_node*nodes ))
        CPU=" -N ${nodes} --ntasks-per-node ${cpus_per_node} "
   else
        CPU=" -n $ncpus $MEM "
   fi
   if [[ ${opt} = debug && ncpus -le 512 && wc_hrs -le 1 ]]
   then  opt="--qos=debug"
   fi
   if [[ $opt = debug ]] ; then opt='' ; fi
   opt="-t ${wc_time}:00 ${CPU} ${type}${OS} $opt"
   if [[ $nargs -lt 1 ]]
   then echo "$action -A ${account}  ${opt}"
        echo "ok to ask for a session with $ncpus Processors for $wc_time hour(s) (n=no+UsageInstructions)"
        read reply
        if [[ $reply = [nN]* ]]
##      then echo "Usage:   $0 [ west | neha | move | visual] ncpus wc_time(HH:MM:SS)"; exit ; fi
        then echo "Usage:   $0 [mov | [d|g][H|S|s|p[1|3]] ncpus[:mem/cpu] [walltime(HH[:MM])]"; exit ; fi
   fi
   echo "************************************"
   echo "* to end the session, type:  exit  *"
   echo "************************************"
   echo "Submitting: $action -A ${account} ${opt}"
   $action -A ${account}  ${opt}
////////////////////////////////////////////////////////////////////////////////////
Remove dir from $PATH variable:
RPATH="/discover/nobackup/ntausnev/ferret_65/bin"
PATH=$( echo ${PATH} | tr -s ":" "\n" | grep -vwE "(${RPATH})" | tr -s "\n" ":" | sed "s/:$//" )

////////////////////////////////////////////////////////////////////////////////////
Merge many PostScript files in one
 gs -sDEVICE=pswrite -sOutputFile=output.ps -dNOPAUSE  -dBATCH phw_*.ps
////////////////////////////////////////////////////////////////////////////////////
Command to merge columns from two separate files into single file?
> cat file1
one two three
one two three
one two three
one two three

> cat file2
four five six
four five six
four five six
four five six

> pr -m -t -s\  file1 file2 | gawk '{print $4,$5,$6,$1}'
four five six one
four five six one
four five six one
four five six one
///////////////////////////////////////////////////////////////////////////////////
Merge concatenate ann files:
cat ann_Eh170_sigma2_vmp.txt ... |  awk '!x[$0]++' > ann_Eh170_sigma2_vmp_1900-????.txt
///////////////////////////////////////////////////////////////////////////////////
To remove the duplicate lines preserving their order in the file use:
awk '!visited[$0]++' your_file > deduplicated_file
////////////////////////////////////////////////////////////////////////////////////
New nodes Reto's script:
/discover/nobackup/projects/giss/exec/qsubIx

///////////////////////////////////////////////////////////////////////////////////
Fortran format
nstead of writing the format directly in the write statement,
it's also possible to use a character variable.

character(len=32) :: my_fmt
my_fmt = '(3f15.3,3f9.2)'
write(*, my_fmt) x, y, z, (var(i), i = 1, nvari)

Now it is possible to manipulate the character variable
to contain the wanted repeat count before the write statement,
using a so-called internal write, or write to internal file.

write(my_fmt, '(a, i0, a)') '(3f15.3,', nvari, 'f9.2)'

(Just make sure the declared length of my_fmt is long enough to contain the entire character string.)
////////////////////////////////////////////////////////////////////////////////////
Interactive nodes on Discover:
export NUM_NODES=2
qsub -I -l select=2:ncpus=12,walltime=12:00:00

////////////////////////////////////////////////////////////////////////////////////
Restore files from modelE archive:
on_ut   E134TcadiRCP45aF40oQ32              # runId
from_ut  annE134TcadiRCP45aF40oQ32_2006-2050 # look at as is packed

////////////////////////////////////////////////////////////////////////////////////

////////////////////////////////////////////////////////////////////////////////////
gs and gv on ACES machine
cygwin window
export DISPLAY=:0
cd /cygdrive/c/Users/ntausnev/DISCOVER4
gv file.ps
////////////////////////////////////////////////////////////////////////////////////
look at netcdf file:
 /usr/local/other/SLES11.1/ncview/2.1.2/intel-12.1.0.233/bin/ncview natl_1850-2005_Eh135s0a.nc
////////////////////////////////////////////////////////////////////////////////////
wget --no-check-certificate https://pypi.python.org/packages/source/E/EasyPlot/EasyPlot-1.0.0.zip -O outFile
////////////////////////////////////////////////////////////////////////////////////
Unpack subdd files:
/discover/nobackup/projects/giss/exec/scaleacc_himem_new APR3000.subddEh134Ti_4xCO2b.nc all
////////////////////////////////////////////////////////////////////////////////////
KDE installation:
sudo dnf groupinstall -y "KDE Plasma Workspaces"

////////////////////////////////////////////////////////////////////////////////////
git checkout AR5_v2_branch

How to in Git, clone a remote repository from a specifed date
Cloning the repository will give you the entire commit history of all the source code.

You need only scroll back through git log and find the desired commit
on your target date.
Running git checkout SHA where SHA is the commit hash will give you
the state of the source code on that date.

git status
git log --since=2014-08-25 --until=2014-08-30   # will help narrow it down!
git checkout 9f240b4b3319f6ee1d5efa37e4b9ee7a261af376

////////////////////////////////////////////////////////////////////////////
How many files in directories and subdirs:
 find . -type d | xargs ls -1 | \
   perl -lne 'if(/^\./ || eof){print $a." ".$count;$a=$_;$count=-1}else{$count++}' | \
   sort -g -k 2
////////////////////////////////////////////////////////////////////////////////////
Quota on Dirac
ssh dirac
quota -Q
////////////////////////////////////////////////////////////////////////////////////
Interactive node on Discover:
#xsub -I -W group_list=s1001 -q general_small -l nodes=${NUM_NODES}:ppn=12,walltime=1:00:00 /usr/bin/ksh
qsub -I -q nccs3 -l select=2:ncpus=12,walltime=12:00:00

/usr/slurm/bin/xsub -I -W group_list=s1001 -l walltime=1:00:00,select=2:ncpus=12 -q debug  # Igor

////////////////////////////////////////////////////////////////////////////////////
Python mathplotlib on Discover:
module load lib/mkl-14.0.0.080 other/comp/gcc-4.6.3-sp1 other/SIVO-PyD/spd_1.13.0_gcc-4.6.3-sp1
////////////////////////////////////////////////////////////////////////////////////
PYTHON:
As a bonus, here is a one-liner for calculating the mode using
a dict comprehension (assuming the list variable is named data):

number, mode = max(dict((k, data.count(k)) for k in data).items(), key=lambda i: i[1])

(It may not be the fastest way to calculate it, but one-liners are fun!)

//////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////
Fortran open file
      open( unit=nfr, file="", form="unformatted" ,convert='BIG_ENDIAN')

//////////////////////////////////////////////////////////////////
EOF :
http://www.cgd.ucar.edu/cas/cassoftware.html
http://www.cgd.ucar.edu/cas/software/list.html

In smoothing potentially non-stationary climate time series
http://www.meteo.psu.edu/holocene/public_html/shared/articles/MannGRL04.pdf


BELOW ARE ALL PROPOSED EXERCISES FOR TOPICS IN TIME SERIES ANALYSIS
http://clivac.eri.ucsb.edu/excercises.html

//////////////////////////////////////////////////////////////////
Send mail to ACES:
cat Eh155bh.ps | Mail -s Eh155bh -a Eh155bh.ps nikolai.l.tausnev@nasa.gov
//////////////////////////////////////////////////////////////////
list subdirectories
 ls -p | grep "/" | grep Eh_s
//////////////////////////////////////////////////////////////////
Vim colors
last256 : A dark vim color-scheme, based on vim-hybrid
https://github.com/sk1418/last256

hybrid.vim : A dark colourscheme combining Jellybeans, Solarized and
Tomorrow-Night
https://github.com/altercation/vim-colors-solarized

////////////////////////////////////////////////////////////////
TotalVIEW on Discover 03.01.13 - 09:31
xsub -I -V -l select=2:ncpus=12,walltime=12:00:00
module purge; module load comp/intel-13.1.0.146  mpi/impi-4.0.3.008 tool/tview-8.9.2.2
print $TVDSVRLAUNCHCMD # expected ssh
mpdboot -n 2 -r ssh -f $PBS_NODEFILE
totalview a.out
//////////////////////////////////////////////////////////////////
Generate fortran code read netcdf file:
ncdump  -h susana.q.1000.7808.nc  | ncgen -f

Read/Modify/Create netcdf files in fortran90

It can be convenient to read netcdf files in your fortran scripts,
or to create fortran scripts to treat large netcdf files.
For this, you can use the netcdf-fortran library.

Here is an example of very basic fortran program that can be used to read
a netcdf file, create or modify a variable and create a new netcdf
file that is similar to the first one:

example.f90

A way to compile and execute it (e.g. with the ifort compiler) is :
    NC_INC="-I /apps/netcdf/4.2.1.1/include"  ## to adapt
    NC_LIB="-L /apps/netcdf/4.2.1.1/lib -lnetcdf -lnetcdff" ## to adapt
    ifort -c $NC_INC example.f90
    ifort -o run_example example.o $NC_LIB
    ./run_example

NB1: to find the netcdf path, you can try to execute: locate libnetcdf.a
NB2: if you want to install the libraries yourself, check:
http://lgge.osug.fr/personnels/Jourdain_Nicolas/Useful_libraries.html


//////////////////////////////////////////////////////////////////
Repository for post processing Hycom data:
git clone ntausnev@simplex.giss.nasa.gov:/giss/gitrepo/GISS_Source.git
git add AVERAGES  CENSUS
git commit -m "Added plotting diagnostics scripts for Hycom ocean"
git push
//////////////////////////////////////////////////////////////////
To count the number of files recursively in the current and all directories
below it, use:

find . -type f | wc -l
for D in *; do echo $D; find $D -type f| wc -l; done > z_list_files


//////////////////////////////////////////////////////////////////
Convert ps ==> png
 gimp
 display E2cvs4m_hyc1.png

 convert tvg.ps tvg.png
 display tvg.png

fileName=avg_ov_Eh_sig1a_2390-2399; epstopdf ${fileName}.eps; \
convert -density 100 ${fileName}.pdf ${fileName}.png; display ${fileName}.png


//////////////////////////////////////////////////////////////////
Script to find the average of a given column and also for specified number of rows
Hi friends
I have 100 files in my directory. Each file look like this..

Temp1 Temp2 Temp3
MAS 1 2 3
MAS 4 5 6
MAS 7 8 9
Delhi 10 11 12
Delhi 13 14 15
Delhi 16 17 18
Delhi 20 21 19
Mumbai 22 46 56
Mumbai 67 34 54
..................................
.................................. so on.

for filename in *
do
  printf "Average for %s = " "$filename"
  awk '/^MAS/ || /^Delhi/ { ++n; sum += $3 }
        END { print sum / n }
  ' "$filename"
done

//////////////////////////////////////////////////////////////////
You can also extract those files  from tar archive that match
a specific globbing pattern
(wildcards). For example, to extract from cbz.tar all files that begin with pic,
no matter their directory prefix, you could type:

 tar -xf E135RCP45aF40oQ32_2006-2050.tar --wildcards --no-anchored 'zostoga_Omon_GISS-E2-R_*'
//////////////////////////////////////////////////////////////////
Find substrig in string:
$ string="TMAXE_hemis"; word="_hemis"; test "${string#*$word}" != "$string" && echo "$word found in $string"
_hemis found in TMAXE_hemis

//////////////////////////////////////////////////////////////////
This opinionated guide was written for my best-practices guide
The HitchhikerÃƒÂ¢Ã‚Â€Ã‚Â™s Guide to Python!
http://docs.python-guide.org/en/latest/

//////////////////////////////////////////////////////////////////
Repository Structure and Python
http://www.kennethreitz.com/repository-structure-and-python.html
//////////////////////////////////////////////////////////////////
Your entire project, in a single glance. TODO !!
https://trello.com/landing
//////////////////////////////////////////////////////////////////
git-notes - Add or inspect object notes
http://schacon.github.com/git/git-notes.html

Automatically Push A Git Repo On Commit
cd my_repo echo 'git push' &gt; .git/hooks/post-commit chmod 755
.git/hooks/post-commit

//////////////////////////////////////////////////////////////////
args
Argument Parsing for Humans.
https://github.com/kennethreitz/args
//////////////////////////////////////////////////////////////////
sh (previously pbs) is a full-fledged subprocess interface for Python that
allows you to call any program as if it were a function:

http://amoffat.github.com/sh/index.html
//////////////////////////////////////////////////////////////////
pre_event ()
{
# Add anything that you want to execute in this function. You can
# hard-code the tasks in this function or create an external shell
# script and execute the external function here.
: # no-op: The colon (:) is a no-op character. It does nothing and
# always produces a 0, zero, return code.
}
###################################################################
post_event ()
{
# Add anything that you want to execute in this function. You can
# hard-code the tasks in this function or create an external shell
# script and execute the external function here.
: # no-op: The colon (:) is a no-op character. It does nothing and
# always produces a 0, zero, return code.
}
###################################################################
usage ()
{
echo "\nUSAGE: $THISSCRIPT \"One or More Filenames to Download\" \n"
exit 1
}
###################################################################
usage_error ()
{
echo "\nERROR: This shell script requires a list of one or more
files to download from the remote site.\n"
usage
}
###################################################################
##################### BEGINNING OF MAIN ###########################
###################################################################
# Test to ensure that the file(s) is/are specified in the $1
# command-line argument.
(($# != 1)) && usage_error
pre_event
# Connect to the remote site and begin the here document.
ftp -i -v -n $RNODE <<END_FTP
user $USER $UPASSWD
binary
lcd $LOCALDIR
cd $REMOTEDIR
mput $LOCALFILES
bye
END_FTP
post_event
/////////////////////////////////////////////////////////////////
#===================================================================
s_timestamp()   # (c) RHReepe. Returns string (YYYY-Mon-DD@HH:MM:SS)
#===================================================================
{
    date "+%Y-%h-%d@%H:%M:%S"
}
#===================================================================
s_now() # (c) RHReepe. Returns string (YYYYMMDDHHMMSS)
#===================================================================
{
    date +%Y%m%d%H%M%S
}
#===================================================================
s_time()    # (c) RHReepe. Returns string (HHMMSS)
#===================================================================
{
    date +%H%M%S
}
====================================================================
s_date()    # (c) RHReepe. Returns string (YYYYMMDD)
#===================================================================
{
    date +%Y%m%d
}

#=====================================================================
s_month_length()    # (c) RHReepe. Returns number of days in MONTH (INT)
#=====================================================================
# Arg_1 = MONTH_NUMBER
{
    if [ $1 -lt 1 ] || [ $1 -gt 12 ]
    then
    echo "$0:s_month_length(): [$1] \
         is not between 1 and 12"
    exit
    fi
    lengths="312831303130313130313031"
    cut2=`expr $1 + $1`
    cut1=`expr $cut2 - 1`
    echo $lengths | cut -c$cut1-$cut2
}

The s_month_length() function is quite simple but watch out for leap years as
there is no account taken of Feb 29th. The fix is actually quite easy too -
just divide the year by 4, then multiply by 4, and see if you get the same
number you started with. You will need to use the bc command for division and
multiplication. If it is the same number then Feb may have 29 days (unless its
a century, or maybe it still does, if it's a millenium!).

Now here are two slightly more complex examples, s_interval() and s_back_date(),
 which get used for checking out superceded archives and timing test functions
or scripts. The function s_interval() is fully in-stream documented. This is a
bit over the top in this example, but you should be able to see how such
treatment enhances understanding when reading the functions. In fact the only
additional thing I'll say about this function, is that I use it to time new
scripts and functions to help me tune out any slow operations. It has two
mandatory arguments which can be provided by calling the s_time() function at
each end of the timed process. The output is in the same format (HHMMSS),
don't forget and think that 000120 = 2 minutes, it is 1 minute 20 seconds.

#===================================================================
s_interval()    # (c) RHReepe. Returns a time difference (HH:MM:SS)
#===================================================================
# Arg_1 = start_time (Format - See s_time)
# Arg_2 = stop_time  (Format - See s_time)
{
    h1=`echo $1 | cut -c1-2`    # Get Start Hour
    m1=`echo $1 | cut -c3-4`    # Get Start Minute
    s1=`echo $1 | cut -c5-6`    # Get Start Second
    h2=`echo $2 | cut -c1-2`    # Get Stop Hour
    m2=`echo $2 | cut -c3-4`    # Get Stop Minute
    s2=`echo $2 | cut -c5-6`    # Get Stop Second
    s3=`expr $s2 - $s1`     # Calculate Second Difference
    if [ $s3 -lt 0 ]        # Test for Negative Seconds
    then
    s3=`expr $s3 + 60`  # If yes - add one minute...
    m1=`expr $m1 + 1`       # ... and to subtractor
    fi
    m3=`expr $m2 - $m1`     # Calculate Minute Difference
    if [ $m3 -lt 0 ]        # Test for Negative Minutes
    then
    m3=`expr $m3 + 60`  # If yes - add one hour...
    h1=`expr $h1 + 1`       # ... and to subtractor
    fi
    h3=`expr $h2 - $h1`     # Calculate Hour Difference
    if [ $h3 -lt 0 ]        # Test for Negative Hours
    then
    h3=`expr $h3 + 24`  # If yes - add one day
    fi
    for number in $h3 $m3 $s3   # Loop through numbers...
    do
    if [ $number -lt 10 ]   # If number is single digit...
    then
        /usr/5bin/echo "0$number\c" # ... add leading zero
    else
        /usr/5bin/echo "$number\c"  # ... else - don't
    fi
    done
    echo ""         # Terminate the string
}

//////////////////////////////////////////////////////////////////
Difference time between two date:
t1="08/27/06 05:00:05"; t2="08/29/06 02:21:05";
dt=$(( $( printf "%(%s)T\n" "$t2" ) - $( printf "%(%s)T\n" "$t1" )));
s=$(( dt % 60  )); m=$(( dt % 3600 / 60  )); h=$((dt / 3600));
printf "%02d:%02d:%02d\n" $h $m $s
//////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////
Automatic array indexing
The Korn Shell (ksh) and the Bourne-Again Shell (bash) from version 2 on support
one-dimensional arrays which can be assigned by array[N]=something_or_other and
referenced by ${array[N]}, where N is a number from 0 up (ksh has an upper
limit of 4095 [recent versions of Korn Shell 93 have increased this], bash is
limited only by available memory).
When adding consecutive elements to an array, there is no need to maintain an
index into the array; instead of:
  for c in red green blue white
  do
    array[$n]=$c
    n=$(( $n + 1 ))
  done
   just use:
  for c in red green blue white
  do
    array[${#array[@]}]=$c
  done
    Since array elements start at index 0, the number of elements in the array,
${#array[@]}, is also the number of the next empty element.
More elements can be added at any time using the same syntax.
Of course, it doesn't work on a sparse array, that is, one with unset elements.

//////////////////////////////////////////////////////////////////
Extracting multiple values from a string
Far too often, I see scripts like this:
string="123,456,789"
v1=`echo $string | cut -d, -f1`
v2=`echo $string | cut -d, -f2`
v3=`echo $string | cut -d, -f3`
It uses three calls to an external command (cut) where none is necessary.
External commands are rarely needed to parse a string in a POSIX shell, i
and even using a Bourne shell they can often be avoided.
The shell splits strings into words using the value of the Internal Field
Separator (IFS) variable as the delimiter, so the same thing can be
accomplished this way:
string="123,456,789"
oldIFS=$IFS
IFS=,
set -- $string
v1=$1
v2=$2
v3=$3
IFS=$oldIFS

//////////////////////////////////////////////////////////////////
This function will centre text on a line of a given length:
centre() ## USAGE: centre width text...
{
   c_width=$1
   shift
   c_text="$*"
   c_width=$(( ($c_width + ${#c_text}) / 2 ))
   printf "%${c_width}.${c_width}s\n" "$c_text"
}
   Sample usage:
centre 45 this is centered on 45 characters
centre $COLUMNS this is centred across the entire window

//////////////////////////////////////////////////////////////////
The basic read command does more than just read a line of input.
It strips leading and trailing whitespace, and it processes escape
sequences introduced by a backslash.
The primary function of this is to allow lines to be continued by
ending a line with a backslash.

If a file contains:
This is the first line \
this is a continuation \
and so is this
   Using read, all three lines will be concatenated into a single line with one command:
$ read x < $HOME/txt
$ echo "$x"
This is the first line this is a continuation and so is this
   To prevent backslashes being interpreted, raw mode (-r) is used:
$ read -r x < $HOME/txt
$ echo "$x"
This is the first line \
   If more than one variable is given as an argument to read, the line will be broken up (using the characters in IFS as separators) and assigned to each variable in turn. If there are more words than variables, the last variable will contain the remainder of the line:
$ read -r a b c d  < $HOME/txt
$ printf "%s\n" "a=$a" "b=$b" "c=$c" "d=$d"
a=This
b=is
c=the
d=first line \
   Or, without using raw mode:
$ read  a b c d  < $HOME/txt
$  printf "%s\n" "a=$a" "b=$b" "c=$c" "d=$d"
a=This
b=is
c=the
d=first line     this is a continuation          and so is this

//////////////////////////////////////////////////////////////////
To toggle a variable between two values, I use this var_toggle function:
var_toggle()
{
    eval "_VAR_TOGGLE=\$$1"
    [ ${_VAR_TOGGLE:-0} = ${3:-0} ] &&
                 _VAR_TOGGLE=${2:-1} ||
              _VAR_TOGGLE=${3:-0}
    eval "$1=\$_VAR_TOGGLE"
}
   The first argument is the name of the variable to be toggled. Successive calls to var_toggle alternate the value of the variable between two values.
If no other arguments are given, the variable is toggled between 1 and 0.
$ var=1
$ var_toggle var; echo $var
0
$ var_toggle var; echo $var
1
$ var_toggle var; echo $var
0
$ var_toggle var; echo $var
1
If one other argument is given, the values alternates between that value and 0.
$ var_toggle var 13; echo $var
0
$ var_toggle var 13; echo $var
13
$ var_toggle var 13; echo $var
0
$ var_toggle var 13; echo $var
13
   If two more arguments are given, the value is toggled between those two.
$ var_toggle var 13 5; echo $var
5
$ var_toggle var 13 5; echo $var
13
$ var_toggle var 13 5; echo $var
5
$ var_toggle var 13 5; echo $var
13

//////////////////////////////////////////////////////////////////
To format one's PATH variable for easy viewing, try this function:
path()
{
    oldIFS=$IFS
    IFS=:
    printf "%s\n" $PATH
    IFS=$oldIFS
}
A typical run of the function:
$ path
/bin
/usr/bin
/usr/bin/X11
/usr/X11R6/bin
/usr/local/bin
/home/chris/bin
/usr/games
/home/chris/scripts
//////////////////////////////////////////////////////////////////
I realized this trend in my own work habits, so I created a simple shell
function to do the hard work for me.

md () {
          mkdir -p $1  &&  cd $1

}
//////////////////////////////////////////////////////////////////
Dead link
find . -type l -print | perl -nle '-e || print'
//////////////////////////////////////////////////////////////////
case $C_STRING in
+([0-9])) echo 'POS_INT' # Integer >= 0
;;
+([-0-9])) echo 'NEG_INT' # Integer < 0
;;
+([a-z])) echo 'LOW_CASE' # lower case text
;;
+([A-Z])) echo 'UP_CASE UPPER' # case text
;;
+([a-z]|[A-Z])) echo 'MIX_CASE' # MIxed CAse text
;;
*) echo 'UNKNOWN' # Anything else
esac
//////////////////////////////////////////////////////////////////
 git clone git://github.com/klen/.vim.git klen_vim
//////////////////////////////////////////////////////////////////
 date +%Y.%m.%d.%T
2012.09.12.11:06:18
//////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////
HANDY ONE-LINERS FOR AWK                                  22 July 2003
compiled by Eric Pement <pemente@northpark.edu>           version 0.22
   Latest version of this file is usually at:
   http://www.student.northpark.edu/pemente/awk/awk1line.txt


USAGE:

    Unix:  awk '/pattern/ {print "$1"}'    # standard Unix shells
 DOS/Win:  awk '/pattern/ {print "$1"}'    # okay for DJGPP compiled
           awk "/pattern/ {print \"$1\"}"  # required for Mingw32

Most of my experience comes from version of GNU awk (gawk) compiled for
Win32. Note in particular that DJGPP compilations permit the awk script
to follow Unix quoting syntax '/like/ {"this"}'. However, the user must
know that single quotes under DOS/Windows do not protect the redirection
arrows (<, >) nor do they protect pipes (|). Both are special symbols
for the DOS/CMD command shell and their special meaning is ignored only
if they are placed within "double quotes." Likewise, DOS/Win users must
remember that the percent sign (%) is used to mark DOS/Win environment
variables, so it must be doubled (%%) to yield a single percent sign
visible to awk.

If I am sure that a script will NOT need to be quoted in Unix, DOS, or
CMD, then I normally omit the quote marks. If an example is peculiar to
GNU awk, the command 'gawk' will be used. Please notify me if you find
errors or new commands to add to this list (total length under 65
characters). I usually try to put the shortest script first.

FILE SPACING:

 # double space a file
 awk '1;{print ""}'
 awk 'BEGIN{ORS="\n\n"};1'

 # double space a file which already has blank lines in it. Output file
 # should contain no more than one blank line between lines of text.
 # NOTE: On Unix systems, DOS lines which have only CRLF (\r\n) are
 # often treated as non-blank, and thus 'NF' alone will return TRUE.
 awk 'NF{print $0 "\n"}'

 # triple space a file
 awk '1;{print "\n"}'

NUMBERING AND CALCULATIONS:

 # precede each line by its line number FOR THAT FILE (left alignment).
 # Using a tab (\t) instead of space will preserve margins.
 awk '{print FNR "\t" $0}' files*

 # precede each line by its line number FOR ALL FILES TOGETHER, with tab.
 awk '{print NR "\t" $0}' files*

 # number each line of a file (number on left, right-aligned)
 # Double the percent signs if typing from the DOS command prompt.
 awk '{printf("%5d : %s\n", NR,$0)}'

 # number each line of file, but only print numbers if line is not blank
 # Remember caveats about Unix treatment of \r (mentioned above)
 awk 'NF{$0=++a " :" $0};{print}'
 awk '{print (NF? ++a " :" :"") $0}'

 # count lines (emulates "wc -l")
 awk 'END{print NR}'

 # print the sums of the fields of every line
 awk '{s=0; for (i=1; i<=NF; i++) s=s+$i; print s}'

 # add all fields in all lines and print the sum
 awk '{for (i=1; i<=NF; i++) s=s+$i}; END{print s}'

 # print every line after replacing each field with its absolute value
 awk '{for (i=1; i<=NF; i++) if ($i < 0) $i = -$i; print }'
 awk '{for (i=1; i<=NF; i++) $i = ($i < 0) ? -$i : $i; print }'

 # print the total number of fields ("words") in all lines
 awk '{ total = total + NF }; END {print total}' file

 # print the total number of lines that contain "Beth"
 awk '/Beth/{n++}; END {print n+0}' file

 # print the largest first field and the line that contains it
 # Intended for finding the longest string in field #1
 awk '$1 > max {max=$1; maxline=$0}; END{ print max, maxline}'

 # print the number of fields in each line, followed by the line
 awk '{ print NF ":" $0 } '

 # print the last field of each line
 awk '{ print $NF }'

 # print the last field of the last line
 awk '{ field = $NF }; END{ print field }'

 # print every line with more than 4 fields
 awk 'NF > 4'

 # print every line where the value of the last field is > 4
 awk '$NF > 4'

# print the j'th field of the i'th line
awk -v i=5 -v j=3 'FNR == i {print $j}'

To print the third field of the fifth line:
awk 'FNR == 5 {print $3}'
awk '/^2171.00/,/^2171.92/' mon_Eh155_2170-2179.txt

To display all the lines from x to y,
you can use awk command in the following manner:

 awk 'NR>=20 && NR<=25' lines.txt


TEXT CONVERSION AND SUBSTITUTION:

 # IN UNIX ENVIRONMENT: convert DOS newlines (CR/LF) to Unix format
 awk '{sub(/\r$/,"");print}'   # assumes EACH line ends with Ctrl-M

 # IN UNIX ENVIRONMENT: convert Unix newlines (LF) to DOS format
 awk '{sub(/$/,"\r");print}

 # IN DOS ENVIRONMENT: convert Unix newlines (LF) to DOS format
 awk 1

 # IN DOS ENVIRONMENT: convert DOS newlines (CR/LF) to Unix format
 # Cannot be done with DOS versions of awk, other than gawk:
 gawk -v BINMODE="w" '1' infile >outfile

 # Use "tr" instead.
 tr -d \r <infile >outfile            # GNU tr version 1.22 or higher

 # delete leading whitespace (spaces, tabs) from front of each line
 # aligns all text flush left
 awk '{sub(/^[ \t]+/, ""); print}'

 # delete trailing whitespace (spaces, tabs) from end of each line
 awk '{sub(/[ \t]+$/, "");print}'

 # delete BOTH leading and trailing whitespace from each line
 awk '{gsub(/^[ \t]+|[ \t]+$/,"");print}'
 awk '{$1=$1;print}'           # also removes extra space between fields

 # insert 5 blank spaces at beginning of each line (make page offset)
 awk '{sub(/^/, "     ");print}'

 # align all text flush right on a 79-column width
 awk '{printf "%79s\n", $0}' file*

 # center all text on a 79-character width
 awk '{l=length();s=int((79-l)/2); printf "%"(s+l)"s\n",$0}' file*

 # substitute (find and replace) "foo" with "bar" on each line
 awk '{sub(/foo/,"bar");print}'           # replaces only 1st instance
 gawk '{$0=gensub(/foo/,"bar",4);print}'  # replaces only 4th instance
 awk '{gsub(/foo/,"bar");print}'          # replaces ALL instances in a line

 # substitute "foo" with "bar" ONLY for lines which contain "baz"
 awk '/baz/{gsub(/foo/, "bar")};{print}'

 # substitute "foo" with "bar" EXCEPT for lines which contain "baz"
 awk '!/baz/{gsub(/foo/, "bar")};{print}'

 # change "scarlet" or "ruby" or "puce" to "red"
 awk '{gsub(/scarlet|ruby|puce/, "red"); print}'

 # reverse order of lines (emulates "tac")
 awk '{a[i++]=$0} END {for (j=i-1; j>=0;) print a[j--] }' file*

 # if a line ends with a backslash, append the next line to it
 # (fails if there are multiple lines ending with backslash...)
 awk '/\\$/ {sub(/\\$/,""); getline t; print $0 t; next}; 1' file*

 # print and sort the login names of all users
 awk -F ":" '{ print $1 | "sort" }' /etc/passwd

 # print the first 2 fields, in opposite order, of every line
 awk '{print $2, $1}' file

 # switch the first 2 fields of every line
 awk '{temp = $1; $1 = $2; $2 = temp}' file

 # print every line, deleting the second field of that line
 awk '{ $2 = ""; print }'

 # print in reverse order the fields of every line
 awk '{for (i=NF; i>0; i--) printf("%s ",i);printf ("\n")}' file

 # remove duplicate, consecutive lines (emulates "uniq")
 awk 'a !~ $0; {a=$0}'

 # remove duplicate, nonconsecutive lines
 awk '! a[$0]++'                     # most concise script
 awk '!($0 in a) {a[$0];print}'      # most efficient script

 # concatenate every 5 lines of input, using a comma separator
 # between fields
 awk 'ORS=%NR%5?",":"\n"' file



SELECTIVE PRINTING OF CERTAIN LINES:

 # print first 10 lines of file (emulates behavior of "head")
 awk 'NR < 11'

 # print first line of file (emulates "head -1")
 awk 'NR>1{exit};1'

  # print the last 2 lines of a file (emulates "tail -2")
 awk '{y=x "\n" $0; x=$0};END{print y}'

 # print the last line of a file (emulates "tail -1")
 awk 'END{print}'

 # print only lines which match regular expression (emulates "grep")
 awk '/regex/'

 # print only lines which do NOT match regex (emulates "grep -v")
 awk '!/regex/'

 # print the line immediately before a regex, but not the line
 # containing the regex
 awk '/regex/{print x};{x=$0}'
 awk '/regex/{print (x=="" ? "match on line 1" : x)};{x=$0}'

 # print the line immediately after a regex, but not the line
 # containing the regex
 awk '/regex/{getline;print}'

 # grep for AAA and BBB and CCC (in any order)
 awk '/AAA/; /BBB/; /CCC/'

 # grep for AAA and BBB and CCC (in that order)
 awk '/AAA.*BBB.*CCC/'

 # print only lines of 65 characters or longer
 awk 'length > 64'

 # print only lines of less than 65 characters
 awk 'length < 64'

 # print section of file from regular expression to end of file
 awk '/regex/,0'
 awk '/regex/,EOF'

 # print section of file based on line numbers (lines 8-12, inclusive)
 awk 'NR==8,NR==12'

 # print line number 52
 awk 'NR==52'
 awk 'NR==52 {print;exit}'          # more efficient on large files

 # print section of file between two regular expressions (inclusive)
 awk '/Iowa/,/Montana/'             # case sensitive


SELECTIVE DELETION OF CERTAIN LINES:

 # delete ALL blank lines from a file (same as "grep '.' ")
 awk NF
 awk '/./'


CREDITS AND THANKS:

Special thanks to Peter S. Tillier for helping me with the first release
of this FAQ file.

For additional syntax instructions, including the way to apply editing
commands from a disk file instead of the command line, consult:

"sed & awk, 2nd Edition," by Dale Dougherty and Arnold Robbins
  O'Reilly, 1997
"UNIX Text Processing," by Dale Dougherty and Tim O'Reilly
  Hayden Books, 1987
"Effective awk Programming, 3rd Edition." by Arnold Robbins
  O'Reilly, 2001

To fully exploit the power of awk, one must understand "regular
expressions." For detailed discussion of regular expressions, see
"Mastering Regular Expressions, 2d edition" by Jeffrey Friedl
   (O'Reilly, 2002).

The manual ("man") pages on Unix systems may be helpful (try "man awk",
"man nawk", "man regexp", or the section on regular expressions in "man
ed"), but man pages are notoriously difficult. They are not written to
teach awk use or regexps to first-time users, but as a reference text
for those already acquainted with these tools.

USE OF '\t' IN awk SCRIPTS: For clarity in documentation, we have used
the expression '\t' to indicate a tab character (0x09) in the scripts.
All versions of awk, even the UNIX System 7 version should recognize
the '\t' abbreviation.

#---end of file---


//////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////
scp ==>
Multiple files can be specified separated by a space like this

$ scp foo.txt bar.txt username@remotehost:/path/directory/

To copy multiple files from remote host to current local directory
$ scp username@remotehost:/path/directory/\{foo.txt,bar.txt\} .
$ scp root@192.168.1.3:~/\{abc.log,cde.txt\} .

 Copy entire directory (recursively)
from one host to another use the r switch and specify the directory
$ scp -v -r ~/Downloads root@192.168.1.3:/root/Downloads

Copy files across 2 remote hosts
Scp can copy files from 1 remote host to another remote host as well.
$ scp user1@remotehost1:/some/remote/dir/foobar.txt user2@remotehost2:/some/remote/dir/

Speed up the transfer with compression
$ scp -vrC ~/Downloads root@192.168.1.3:/root/Downloads
In the above example we moved the entire directory with compression enabled.
The speed gain would depend on how much the files could be compressed.

Copy files from discover to local PC:


Cygwin window:
CHECK on Windows desktop!!!
Create directories: C:\Users\ntausnev\DISCOVER4 and C:\Users\ntausnev\DISCOVER2

==========================================
Discover ----> Local (ACES) PC machine
==========================================
scp ntausnev@discover.nccs.nasa.gov:/discover/dir/file /cygdrive/c/Users/ntausnev/DISCOVER4/.
Examples:
scp ntausnev@discover.nccs.nasa.gov:/discover/nobackup/ntausnev/Z_Deleted_Files/z2ODIN/*.ps /cygdrive/c/Users/ntausnev/DISCOVER4/.
scp ntausnev@discover.nccs.nasa.gov:/home/ntausnev/POST_PROC_TNL_nc/RUNS_LIST_AR5_H /cygdrive/c/Users/ntausnev/DISCOVER4/.

==========================================
Local PC computer ----> DISCOVER (/discover/nobackup/ntausnev/Z_Del/discover/nobackup/ntausnev/Z_Deleted_Files/)
==========================================
scp Local_file_on_pc ntausnev@discover.nccs.nasa.gov:/discover/nobackup/ntausnev/Z_Deleted_Files/.
Examples: (put files at DISCOVER2 directory)
scp /cygdrive/c/Users/ntausnev/DISCOVER2/cdfout.tar ntausnev@discover.nccs.nasa.gov:/discover/nobackup/ntausnev/Z_Deleted_Files/.

From Downloads on Local PC to discover:
cd  /cygdrive/c/Users/ntausnev/Downloads
scp /cygdrive/c/Users/ntausnev/Downloads/nameLocalFile ntausnev@discover.nccs.nasa.gov:/discover/nobackup/ntausnev/Z_Deleted_Files/.


//////////////////////////////////////////////////////////////////
#!/bin/bash
# Colors
red='\e[0;31m';
cyan='\e[0;36m';
nc='\e[0m';

alert () { echo; echo -e  ${red}${1}${cyan} not found! Attempting to install...  $nc;  }
print () { echo; echo -e  ${cyan} ${1}${nc};  }

//////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////
Interactive session on Discover
$  qsubI
/usr/pbs/bin/qsub -I -W group_list=s1001 -l walltime=12:00:00,select=2:mpiprocs=12:proc=west
//////////////////////////////////////////////////////////////////
Find and delets:
find . -name "FILE-TO-FIND"-exec rm -rf {} \;
//////////////////////////////////////////////////////////////////
Latex on discover:
 pdflatex lsn_cv.text
 gv lsn_cv.pdf
 gs lsn_cv.pdf

 latex abc.tex
 dvipdfm abc.dvi
//////////////////////////////////////////////////////////////////
I'm using the following to count the number of files in a directory, and its
subdirectories:

find . -type f | wc -l

//////////////////////////////////////////////////////////////////
How to replace multiple white spaces from a string:
Code:
# echo 'some     white            spaces' | sed 's/  */\ /g'
some white spaces
//////////////////////////////////////////////////////////////////
Sed Find and Display Text Between Two Strings or Words
$ sed -n '/WORD1/,/WORD2/p' /path/to/file
$ sed -n '/FOO/,/BAR/p' test.txt

//////////////////////////////////////////////////////////////////
gi would get you back where you where editing.
//////////////////////////////////////////////////////////////////
Suppose I had a plaintext table loaded into a Vim buffer containing
the name, subject matter expertise, birth year, and nationality of
a few well-known programmers:

Stallman  Richard GNU 1953  USA
Wall  Larry   Perl  1954  USA
Moolenar  Bram  Vim 1961  Netherlands
Tridgell  Andrew  Samba  1967  Australia
Matsumoto  Yukihiro  Ruby  1965  Japan
Ritchie  Dennis  C  1941  USA
Thompson  Ken  Unix  1943  USA
Actually, that kind of untidy.

:%!column -t

Stallman   Richard   GNU    1953  USA
Wall       Larry     Perl   1954  USA
Moolenar   Bram      Vim    1961  Netherlands
Tridgell   Andrew    Samba  1967  Australia
Matsumoto  Yukihiro  Ruby   1965  Japan
Ritchie    Dennis    C      1941  USA
Thompson   Ken       Unix   1943  USA
May as well sort it by surname too:

:%!sort -k1

Matsumoto  Yukihiro  Ruby   1965  Japan
Moolenar   Bram      Vim    1961  Netherlands
Ritchie    Dennis    C      1941  USA
Stallman   Richard   GNU    1953  USA
Thompson   Ken       Unix   1943  USA
Tridgell   Andrew    Samba  1967  Australia
Wall       Larry     Perl   1954  USA
//////////////////////////////////////////////////////////////////
Split string
$ echo "12|23|11" | awk '{split($0,a,"|"); print a[1], a[2], a[3]}'
12 23 11


//////////////////////////////////////////////////////////////////
NCO: How to extract specified variable from files
ncrcat -v ta P*.nc  out.nc

how find max/min variable from file
ncwa -O -y max -v varName fileIn.nc fileOut.nc

# Avrg 120 monthly data:
/usr/local/other/SLES11.1/nco/4.4.4/intel-12.1.0.233/bin/ncea  -O \
    sst_???1940-1949.Eh169min_dpc.nc sst_ANN1940-1949.Eh169min_dpc.nc

This is handy when you obtain a file with unfortunate choices of variable,
 dimension, or attribute names.
ncrename -h -O -v old_variable_name,new_variable_name filename.nc
-h: do not add to the history variable
-O: (upper case) overwrite the file.
-d oldname,newname: to change a dimension name
-a oldname,newname: to change an attribute name

//////////////////////////////////////////////////////////////////
 Using netCDF operators (NCO) to concatenate files without a record dimension

Description of the Problem: Imagine you have a set of netcdf files, each with
a single month of a multiyear dataset. In some cases, the time dimension will
not be the record dimension. This means you can't use the netcdf (NCO)
operator ncrcat to concatenate the individual months along the time dimension.
But, there is a work around:

Solution: run the following commands in a bash shell script
[you can get mine here: makeSingleNC.sh]

list=`ls *.nc`
for i in $list;
do
ncecat -O $i $i
ncpdq -O -a time,record $i $i
ncwa -O -a record $i $i
done
ncrcat -h *.nc out.nc

Say we wish to compute the monthly gridpoint anomalies from
the zonal annual mean. A zonal mean is a quantity that has
been averaged over the longitudinal (or x) direction.
First we use ncwa to average over longitudinal direction lon,
creating 85_x.nc, the zonal mean of 85.nc.
Then we use ncbo to subtract the zonal annual means from
the monthly gridpoint data: :

$ ncwa -a lon 85.nc 85_x.nc
$ ncbo ÃƒÂ¢Ã‚Â€Ã‚Â“y sub 85_0112.nc 85_x.nc tx_anm_85_0112.nc




//////////////////////////////////////////////////////////////////
:%y+
to yank all lines in VIM
//////////////////////////////////////////////////////////////////
The R version of Fields is currently available for UNIX, Linux and Windows
http://www.image.ucar.edu/Software/Fields/
//////////////////////////////////////////////////////////////////
Software on Discover
http://www.nccs.nasa.gov/primer/userlocal.html
//////////////////////////////////////////////////////////////////
To view html from console you can use any of the text browsers
available in linux.
Here are the list:
Firefox /Files
lynx
w3m
elinks
//////////////////////////////////////////////////////////////////
Modeline:
# vim:ft=sh:fdm=syntax:nu:
vim:tw=78:ts=8:noet:ft=help:norl:

I can never remember what those comments that change vim settings are called,
and spend hours trawling through vim help. They are called modelines.
:help modeline brings up the documentation.

Some typical modelines for copying and pasting:


Text files
# vim:tw=75
# vim:textwidth=75

Shell/Bash
# vim: ai ts=4 sts=4 et sw=4 ft=sh
# vim: autoindent tabstop=4 shiftwidth=4 expandtab softtabstop=4 filetype=sh

Ruby
# vim: ai ts=2 sts=2 et sw=2 ft=ruby
# vim: autoindent tabstop=2 shiftwidth=2 expandtab softtabstop=2 filetype=ruby

Python
# vim: ai ts=4 sts=4 et sw=4 ft=python
# vim: autoindent tabstop=4 shiftwidth=4 expandtab softtabstop=4 filetype=python

Perl
# vim: ai ts=4 sts=4 et sw=4 ft=perl
# vim: autoindent tabstop=4 shiftwidth=4 expandtab softtabstop=4 filetype=perl
//////////////////////////////////////////////////////////////////
2- Modify netcdf files using the NCO tools

NCO tools consist of several powerful commands to read/modify/create netcdf
 files. The full documentation can be found [here].
Some simple basic command lines are shown here as an example.

To rename variable var1 as "newvar" or dimension x as "lon" :
    ncrename -O -v var1,newvar filein.nc fileout.nc
    ncrename -O -d x,lon filein.nc fileout.nc

To crop a netcdf file, i.e. to reduce the domain size (with option -F
   indices start at 1):

    ncks -F -d time,1,10 filein.nc fileout.nc
    ncks -F -d x,92,111 filein.nc fileout.nc
And similarly, if you have a well written netcdf files (with appropriate
    attributes) and a lon-lat grid, you may be able to use (don't forget
    the dots in the numbers):

    ncks -d lat,-30.0,30.0 filein.nc fileout.nc

To only keep variables var1 and var2 in a netcdf file (option -O is to
    overwritte):

    ncks -O -v var1,var2 filein.nc fileout.nc
To remove variables var1 and var2 from a netcdf file:
    ncks -O -x -v var1,var2 filein.nc fileout.nc

To merge two files of same dimension (name and size), e.g. file1.nc
   containing the variable var(x,y) and file2.nc containing the variables
   nav_lon(x,y), nav_lat(x,y) and Bathymetry(x,y), you can do as follows:
    ncks -A file1.nc file2.nc
The variable var(x,y) will then be included into file2.nc

To concatenate files with the same variables and consecutive time steps
(e.g. there is one file per month [whatever the output frequency within
this file] and you want a file containing the JJAS months):
    ncrcat JUN1979.nc JUL1979.nc AUG1979.nc SEP1979.nc JJAS_1979.nc

To calculate time-averages, e.g. to calculate a monthly mean from
a file containing daily outputs:
    ncra -F -d time,1,31 file_January_daily.nc file_January_monthly.nc
This can also be used to calculate mean Jan/Feb/March/... over
a multi-year file:
    ncra -F -d time,1,1872,12 tos_monthly_1850-2005.nc tos_mean_JAN.nc
    ncra -F -d time,2,1872,12 tos_monthly_1850-2005.nc tos_mean_FEB.nc
    ncra -F -d time,3,1872,12 tos_monthly_1850-2005.nc tos_mean_MAR.nc

Here are a few examples showing how to modify netcdf attributes
(see NCO user guide for further information).
To delete attribute "standard_name" for variable "var1":
    ncatted -a standard_name,var1,d,, filein.nc fileout.nc
To modify existing attribute "long_name" of character type for variable var1:
    ncatted -a long_name,var1,m,c,'temperature' filein.nc fileout.nc
To create non-existing attribute "units" of character type for variable var1:
    ncatted -a units,var1,c,c,'K' filein.nc fileout.nc
Add attribute "positive" of character type for variable "Depth"
    ncatted -a positive,Depth,a,c,"down" z_in.nc


Finally, a very powerful command is ncap2. Again, there is a large number
of possibilities, see NCO user guide for further information.
A few examples are given here:

To calculate new variable called KE from existing uu and vv variables:
    ncap2 -F -s "KE=0.5*(uu*uu+vv*vv)" file_in.nc file_out.nc
To create a land mask variable (sftlf) based on SST (tos) values :
    ncap2 -F -s "sftlf=tos(1,:,:)*0.0 ; \\
sftlf = sftlf.delete_miss() ; \\
sftlf(:,:) = 100.0 ; \\
where( tos(1,:,:) > 260.0 || tos(1,:,:) < 310.0 ) sftlf=0.0" \\
filein.nc fileout.nc
To use a loop to fill existing variable X from index 1 to index 482:
    ncap2 -F -s \\
"idx=1 ; while(idx<482){X(idx) = 20.0+0.75*idx; idx++;}" \\
filein.nc fileout.nc


Usefull cdo commands

To check whether two netcdf files are identical, or to find where small differences are :
    cdo diffn file1.nc file2.nc

NCO extract variable and change missing_value and  _FillValue:
ncks -O -v Temp ANN_3610-3619.zoutEhEnso.nc z.nc
ncatted -a missing_value,Temp,o,f,-1.0e34 z.nc
ncatted -a _FillValue,Temp,o,f,-1.0e34 z.nc
ncap2 -O -s 'where(Temp<=-500.0) Temp=-1.E+34' z.nc out.nc

Replace variable value in nercdf file
ncap2 -O -s 'where(sst == -1000.) sst=-1.8' z1_tmp.nc z0_tmp.nc

Extract time record from record 1657 until end of file:
ncks -h -O -F -d time,1657, HadISST_ice.nc 2008onward.nc

Extract nrec1 - nrec2 from .nc file
ncks -h -O -F -d time,nrec1,nrec1+nrec2-1 HadISST_ice.nc nrec1_nrec2.nc

Print values of variable:
ncks -F -v  tsurf_hemis  tsurf_hemis_ANN_1850-1895.E135f9aF40oQ32.nc

How do I change some values of a particular variable in a bunch
of my netcdf files? Here's what I wish to do:
Change variable "zaxis = 1, 2, 3;" to "zaxis = 0.3, 0.6, 0.9;"
ncap2 --ovr -s 'zaxis(:)={0.33,0.66,0.99}' filex.nc x.nc

at the end I made the time dimension netCDF conform by attending some attributes:
ncatted -a calendar,time,c,c,"proleptic_gregorian" foo.nc
ncatted -a long_name,time,c,c,"time"  foo.nc
ncatted -a units,time,c,c,"day as %Y%m%d.%f"  foo.nc

extract values variable svn within a specific time and lon lat range
ncks -v snc -d lat,79,95 -d lon,0,25 -d time,0,5 infile.nc -O outfile.nc
ncks -F -v SUL  -d time,01,12 -d lon,12,12,1 -d lat,12,12,1  ${fileIn} z.nc

//////////////////////////////////////////////////////////////////
NCO integration:
Use ncwa and use the  -N (integration, not average) option
z0=0.0 # REAL!!! Integers are interpretated by ncwa as array indices
z1=2000.0

ncwa -O -N -a lev -d lev,${z0},${z1} -w masscello ann_avg.nc ohc_ij.nc # depth integral

Note: nco will include every layer with mean depth up to 2000 m.
 If the deepest layer whose midpoint is less than 2000 m extends
 from 1900 to 2100 m, your sum will really be from 0 to 2100 m.
//////////////////////////////////////////////////////////////////

NCO average:
You need to weight your average

ncwa -O -w mo -v heat -a zoc -d zoc,0.,2000. filein.nc fileout.nc

//////////////////////////////////////////////////////////////////

Python: Customizing matplotlib

The matplotlibrc file
matplotlib uses matplotlibrc configuration files to customize
all kinds

of properties, which we call rc settings or rc parameters. You can control
the defaults of almost every property in matplotlib: figure size and dpi,

 line width, color and style, axes, axis and grid properties, text and
font properties and so on. matplotlib looks for matplotlibrc in three
locations, in the following order:

1.matplotlibrc in the current working directory, usually used for
specific customizations that you do not want to apply elsewhere.
2..matplotlib/matplotlibrc, for the userÃƒÂ¢Ã‚Â€Ã‚Â™s default customizations.
 See .matplotlib directory location.
3.INSTALL/matplotlib/mpl-data/matplotlibrc, where INSTALL is something l
ike /usr/lib/python2.5/site-packages on Linux, and maybe
 C:\Python25\Lib\site-packages on Windows. Every time you install matplotlib,
 this file will be overwritten, so if you want your customizations to be
saved, please move this file to you .matplotlib directory.
To display where the currently active matplotlibrc file was loaded from,
one can do the following:

>>> import matplotlib
>>> matplotlib.matplotlib_fname()
'/home/foo/.matplotlib/matplotlibrc'

//////////////////////////////////////////////////////////////////
Show wide ps -ef command:
ps -aef --width=256 | grep ntausnev | awk '{for(i=8;i<=NF;i++)printf "%s",$i;print ""}'

//////////////////////////////////////////////////////////////////
Show how many files in subdirs:
find . -type f -printf %h"\n" | sort | uniq -c
//////////////////////////////////////////////////////////////////
Move columns between files:
\tp
The problem: I have  two files, file-1 and file-2, each of which has two
columns; and I want to add the second column of the second file as
the third column in the first file.
Lets say the following is the content of file-1:

A   1
B   2
C   3

and that of file-2:

D   4
E   5
F   6

and I want to have something like this in file-3

A   1   4
B   2   5
C   3   6

Of course, the actual data are not as simple as the above!

Solution:

$ awk '{str1=$1; str2=$2; getline < "file-2"; print str1" \t "str2" \t "$2 > "file-3"}' file-1
I inserted the tab characters (\t) just to make file-3 look nice.
//////////////////////////////////////////////////////////////////

Batch execution of vi from a command file:
Execute: vi -e file-name.html < ViCommands-HtmlUpdate.txt
vim -E -s bob.html <<-EOF
   :%substitute/home.html/index.html/
   :update
   :quit
EOF


ViCommands-HtmlUpdate.txt:
:1,$ s/<P>/<p>/g
:1,$ s/<B>/<b>/g
:1,$ s/<\/B>/<\/b>/g
:1,$ s/<I>/<i>/g
:1,$ s/<\/I>/<\/i>/g
:wq
//////////////////////////////////////////////////////////////////
Moving columns, manipulating fields and awk:
:'t,. !awk '{print $3 " " $2 " " $1}' - This will reverse the order of the
columns in the block of text. The block of text is defined here as from
the line marked with the keystroke "bt" and the current line (".") .
This text block is referenced as "'t,."
              aaa bbb ccc              ccc bbb aaa
              xxx yyy zzz   becomes->  zzz yyy xxx
              111 222 333              333 222 111
//////////////////////////////////////////////////////////////////
python -c "from idlelib import idle"&
//////////////////////////////////////////////////////////////////
The primary function of this is to allow lines to be continued by ending a line with a backslash. If a file contains:

This is the first line \
this is a continuation \
and so is this


Using read, all three lines will be concatenated into a single line with one command:

$ read x < $HOME/txt
$ echo "$x"
This is the first line this is a continuation and so is this


To prevent backslashes being interpreted, raw mode (-r) is used:

$ read -r x < $HOME/txt
$ echo "$x"
This is the first line \


If more than one variable is given as an argument to read, the line will be broken up (using the characters in IFS as separators) and assigned to each variable in turn. If there are more words than variables, the last variable will contain the remainder of the line:

$ read -r a b c d  < $HOME/txt
$ printf "%s\n" "a=$a" "b=$b" "c=$c" "d=$d"
a=This
b=is
c=the
d=first line \


Or, without using raw mode:

$ read  a b c d  < $HOME/txt
$  printf "%s\n" "a=$a" "b=$b" "c=$c" "d=$d"
a=This
b=is
c=the
d=first line     this is a continuation          and so is t...
//////////////////////////////////////////////////////////////////
Extracting multiple values from a string:
The shell splits strings into words using the value of the
Internal Field Separator (IFS) variable as the delimiter,
 so the same thing can be accomplished this way:

string="123,456,789"
oldIFS=$IFS
IFS=,
set -- $string
v1=$1
v2=$2
v3=$3
IFS=$oldIFS

//////////////////////////////////////////////////////////////////
grep -h " has " z_chk_arch_* | grep -v 120
//////////////////////////////////////////////////////////////////
cd /discover/nobackup/ntausnev/RUNS_ME; \
 list_rsf=$(find . -name 1*.rsf*.nc -print > z_rsf_fresh; \
grep -v JAN z_rsf_fresh > \
z_rsf_not_jan; cat z_rsf_not_jan | tr "\n" " "); rm -f $list_rsf

//////////////////////////////////////////////////////////////////
cd /home/ntausnev/POST_PROC_TNL_nc; pack_chem.ksh > \
/discover/nobackup/ntausnev/Z_Deleted_Files/z_CHE/z_log_che 2>&1 &

//////////////////////////////////////////////////////////////////
Start PUTTY with target set to:
Open run dialog: Windows key + r

  "C:\Program Files (x86)\PuTTY\putty.exe"  -load first

//////////////////////////////////////////////////////////////////
Git clone existing repository under the new name:
git clone ntausnev@simplex.giss.nasa.gov:/giss/gitrepo/modelE.git tnl_git_mE

Show branches that exist:
git branch

Create a branch
git branch abcd

Change to branch "xyz":
git checkout xyz

Change back to "master":
git checkout master

Delete the xyz branch
git branch -d xyz

But if you want to work on that branch,
you'll need to create a local tracking branch:

git checkout -b tnl remotes/origin/AR5_branch

//////////////////////////////////////////////////////////////////
cvs checkout -r AR5_branch -d Eh120ttt modelE
//////////////////////////////////////////////////////////////////
      # delete the line 18 from '~/.ssh/known_hosts' file
      sed -i '18 d' ~/.ssh/known_hosts
      # also
      sed -i 18d ~/.ssh/known_hosts
      # delete few lines
      # delete 6 lines from line 8
      sed -i 8,+6d file.txt
      # delete the line where is 'TO DELETE'
      sed -i '/TO DELETE/ d' file.txt

Delete from 4th to 8th line from file.

$ sed '4,8d' thegeekstuff.txt   # Delete lines 4-8

 Delete the lines starting from the pattern 'Linux' till the last line:
$ sed '/Linux/,$d' file
in many files:  sed -i '/2117 /,$d' *.Eh213SSP534OVERa

Finding-and-deleting-lines-from-all-files-recursively
find . -type f -print0 | xargs -0 sed -i /KeyWord/d


You can use Vim in Ex mode:

find -type f -exec ex -sc g/KeyWord/d -cx {} ';'
g global search

d delete

x save and close

//////////////////////////////////////////////////////////////////
ModelE diagnostics:
 scaleacc PARTIAL.accEhirCVS.nc aij

ncdump -h PARTIAL.aijEhirCVS.nc | more
ncdump -h PARTIAL.aijEhirCVS.nc | egrep -i inc
ncdump -h PARTIAL.aijEhirCVS.nc | egrep -i trnf
ncksprt -v trnf_toa_hemis PARTIAL.aijEhirCVS.nc
ncdump -h PARTIAL.aijEhirCVS.nc | egrep -i thermal
ncksprt -v trdn_surf_hemis PARTIAL.aijEhirCVS.nc
ncksprt -v trup_surf_hemis PARTIAL.aijEhirCVS.nc
ncksprt -v trup_surf PARTIAL.aijEhirCVS.nc > pout
ncksprt -v trup_surf -d lon,73 -d lat,67 PARTIAL.aijEhirCVS.nc
ncdump -h PARTIAL.aijEhirCVS.nc | egrep -i ground
ncksprt -v tgrnd -d lon,73 -d lat,67 PARTIAL.aijEhirCVS.nc
ncdump -h PARTIAL.aijEhirCVS.nc | egrep -i lake
ncdump -h PARTIAL.aijEhirCVS.nc | egrep -i temp
ncdump -h PARTIAL.aijEhirCVS.nc | egrep -i temper
ncksprt -v TGO2 -d lon,73 -d lat,67 PARTIAL.aijEhirCVS.nc
ncksprt -v sst -d lon,73 -d lat,67 PARTIAL.aijEhirCVS.nc
ncdump -h PARTIAL.aijEhirCVS.nc | egrep -i irrig
ncksprt -v irrig_w_tot -d lon,73 -d lat,67 PARTIAL.aijEhirCVS.nc
ncksprt -v gml_irrigate -d lon,73 -d lat,67 PARTIAL.aijEhirCVS.nc
ncksprt -v irrig_gwE -d lon,73 -d lat,67 PARTIAL.aijEhirCVS.nc
ncksprt -v mwl_irrigate -d lon,73 -d lat,67 PARTIAL.aijEhirCVS.nc
ncksprt -v irrig_e -d lon,73 -d lat,67 PARTIAL.aijEhirCVS.nc

ncksprt -v trup_surf PARTIAL.aijEhirCVS.nc > pout

head pout
gawk '$3>500{print $0}' pout
gawk '$3>1000{print $0}' pout


USE PARTIAL.aijEhirCVS.nc
 SHADE/I=215:220/J=65:68/K=0/L=0  gwtr[d=PARTIAL.aijEhirCVS]; go land


//////////////////////////////////////////////////////////////////
Russian web about python:
www.habrahabr.ru
//////////////////////////////////////////////////////////////////
find . -type d |
  perl -lne'push @_, $_;
    print join $/,
      sort {
        length $a <=> length $b ||
          $a cmp $b
        } @_ if eof'

//////////////////////////////////////////////////////////////////
find /discover/nobackup/ntausnev/RUNS_ME -name "*.tar" -exec ls -lh {} \;
find DIRECTORY -type f -print0 -iname "*.avi" | xargs -0r myBrandNewFunction
//////////////////////////////////////////////////////////////////
vim chnge order columns:

Moving columns, manipulating fields and awk:
:'t,. !awk '{print $3 " " $2 " " $1}' - This will reverse the order
 of the columns in the block of text. The block of text is defined
here as from the line marked with the keystroke "bt" and the current
 line ("."). This text block is referenced as "'t,."
              aaa bbb ccc              ccc bbb aaa
              xxx yyy zzz   becomes->  zzz yyy xxx
              111 222 333              333 222 111
//////////////////////////////////////////////////////////////////
To copy the entire screen
    *
      Press PRINT SCREEN.
To copy only an active window
    *
      Press ALT+PRINT SCREEN.
//////////////////////////////////////////////////////////////////

Setup from command line:

 export runId=E??? ; make -j6 setup RUN=$runId MP=NO ESMF=YES MPIDISTR=intel \
EXTRA_FFLAGS="-I/usr/local/intel/mpi/4.0.1.007/intel64/include -traceback -V" 2>&1 | tee z_setup_${runId}

 export RUN=???; make -j6 setup RUN=${RUN} COMPILE_WITH_TRAPS=YES SETUP_FLAGS=-wait MP=NO ESMF=YES MPIDISTR=intel \
 EXTRA_FFLAGS="-I/usr/local/intel/mpi/4.0.1.007/intel64/include -traceback -V" 2>&1 | tee z_setup_${RUN}

//////////////////////////////////////////////////////////////////
Delete rsf files:
 rm -rf 1[^J]*.rsf* 1JU*.rsf*
//////////////////////////////////////////////////////////////////
Matlab on dali nodes:
module load tool/matlab-R2009a
matlab  -nojvm -nosplash -nodisplay < ov_1deg_tnl.m  >/dev/null 2>&1

//////////////////////////////////////////////////////////////////
Open Event viewer with windows vista:
In Start button, serach box, type event viewer  and then
list of events, double-click Event Viewer

Startup with Windows vista:
type msconfig and then tab startup.
////////////////////////////////////////////////////////////////

Sometimes we have a file with duplicate lines, and we want
    to print each line only once, e.g.

    bart
    lisa
    bart
    bart
    homer

    Well, "uniq" is made for this purpose, but it only detects
    consecutive duplicate lines. We could use "sort -u", but
    sometimes we don't want the sequence of the input lines
    changed.

    The following "awk" script prints each line once (the output
    being "bart lisa homer", each word on its own line) and does
    not change the sequence of the input lines:

        # printonce - print each line exactly once
        awk '!L[$0]++' "$@"

//////////////////////////////////////////////////////////////////
    print line 5, but
    also continue to read the following 25138 lines, doing what
    it was told to do: ignore them. The following command makes
    "sed" stop reading after line 5:

    lineno=5
    sed -n "${lineno}{p;q;}"

//////////////////////////////////////////////////////////////////
PN=`basename "$0"`          # program name
VER='2.4'

# Change the usage message below if you change anything of this:
: ${COMPRESS:=gzip}
: ${UNCOMPRESS:=gunzip}
: ${COMPRESS_SUFFIX:=.gz}
: ${TMPDIR:=/tmp}

TarFlags=               # Default tar options
Silent=false                # "true" or "false"

usage () {
    echo >&2 "$PN - send files/directories as tar archive via e-mail, $VER
usage: $PN e-mail-address {file|directory} [...]

The program searches all given files and directories (including
subdirectories), creates a compressed \"tar\" archive, and sends it to
the specified e-mail address."
    exit 1
}

error () { echo >&2 "$PN: $*"; }
fatal () { error "$@"; exit 1; }

//////////////////////////////////////////////////////////////////
#!/bin/ksh
#xtitle: set title of xterm to string: e.g. xtitle an example of an
#xterm title
printf "\033]0;$*\007"

//////////////////////////////////////////////////////////////////
dotfiles: list all files beginning with .
ls -a $1 | grep ^[.].*

//////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////
vim colors:
:color earendel
:set background=dark
:set background=light



vim:
Problem starting up vim: "No mapping found"
You can find from where this message comes using
      % vim -V20
or
      % vim -V20 2>&1 | tee logfile
and examiging logfile later. In the logfile, you will see the line number and
script name. Ignore the "Vim: Warning: Output is not to a terminal"
in later case.

BTW, the message "No mapping found" comes from command :map
with lhs but empty rhs, like :map xyz.
//////////////////////////////////////////////////////////////////
Vim: Deleting/selecting spanning multiple lines
d/x
      Delete forward until you find x (exclusive). If x is found, vim
      will delete everything from the current cursor position to, but
      not including x, spanning multiple lines if necessary.

      x doesn't have to be one character. It's most likely to be a word
      or several characters. If you're editing your email, you could use
      this to delete all text up to your signature by executing d/--.

      This is a combination of the (d)elete command and the (/) search
      forward motion command. You may also substitute other commands for
      the delete portion of that command, such as visual by character,
      Visual by line, or yank.
d?x
      Delete backward until you find x (exclusive). If x is found, vim
      will delete everything from the current cursor position to, but
      not including x, spanning multiple lines if necessary.
//////////////////////////////////////////////////////////////////
Give read, write and execute privileges to group (including all
the files in the sub-directories)
Use -R, as shown below to provide the recursive privileges for the
directory and sub-directories (including the files in it).

chmod -R g+rwx /u01
chmod -R ugo+r *
//////////////////////////////////////////////////////////////////
You can see the font name for all installed fonts using the xlsfonts command:
$ xlsfonts
The easiest way to come up with a font name is to do it interactively using the
xfontsel command:
$ xfontsel
//////////////////////////////////////////////////////////////////

To access the color names through the X server, use the following command:
$ showrgb
This permits you to view the exact names that have been loaded into the server without
knowing the rgb.txt file location.
//////////////////////////////////////////////////////////////////
Use chsh to change your default login shell. When you run it, chsh asks
you for your password (for security reasons), and then asks what shell
you'd like your login shell to be replaced with. Your answer must be a shell
that.s
chsh
//////////////////////////////////////////////////////////////////
Getting the Name of Your Current Shell
echo $0
//////////////////////////////////////////////////////////////////
Delete a file starting with a dash/hypen on Linux
on the command line
$ ls -l
total 678586
-rw-r--r-- 1 root root        54 Apr 29 15:39 -.log
-rw-r--r-- 1 root root     26819 Apr 30 13:17 210.5.53.35.log

rm ./-.log
rm -r ./-x    DIRECTORY -x

//////////////////////////////////////////////////////////////////
# reset name of xterm title bar & icon to $NAME
NAME="TNL1"; echo -e "\033]0;${NAME}\007\c"
//////////////////////////////////////////////////////////////////
Here's a great listing of the available colors for xterm:
http://mkaz.com/archives/1092/xterm-colors/
//////////////////////////////////////////////////////////////////
Setup
-----

git clone <repo>
  clone the repository specified by <repo>; this is similar to "checkout" in
  some other version control systems such as Subversion and CVS

Add colors to your ~/.gitconfig file:

  [color]
    ui = auto
  [color "branch"]
    current = yellow reverse
    local = yellow
    remote = green
  [color "diff"]
    meta = yellow bold
    frag = magenta bold
    old = red bold
    new = green bold
  [color "status"]
    added = yellow
    changed = green
    untracked = cyan

Highlight whitespace in diffs

  [color]
    ui = true
  [color "diff"]
    whitespace = red reverse
  [core]
    whitespace=fix,-indent-with-non-tab,trailing-space,cr-at-eol

Add aliases to your ~/.gitconfig file:

  [alias]
    st = status
    ci = commit
    br = branch
    co = checkout
    df = diff
    lg = log -p
    lol = log --graph --decorate --pretty=oneline --abbrev-commit
    lola = log --graph --decorate --pretty=oneline --abbrev-commit --all

//////////////////////////////////////////////////////////////////
Are you using Git in Ubuntu and want to use an external visual diff viewer?
It's easy! I will be using Meld for this example but most visual diff tools
should be similar. If you don't already have Meld, then install it:

sudo apt-get install meld

Ok. Now let's begin by breaking it. Enter this into a terminal:

git config --global diff.external meld

Then navigate to a Git tracked directory and enter this (with an actual filename):

git diff filename

Meld will open but it will complain about bad parameters.
The problem is that Git sends its external diff viewer seven parameters when Meld
only needs two of them; two filenames of files to compare.
One way to fix it is to write a script to format the parameters
before sending them to Meld. Let's do that.

Create a new python script in your home directory
(or wherever, it doesn't matter) and call it diff.py.

#!/usr/bin/python
import sys
import os
os.system('meld "%s" "%s"' % (sys.argv[2], sys.argv[5]))

Now we can set Git to perform it's diff on our new script
(replacing the path with yours):

git config --global diff.external /home/nathan/diff.py
git diff filename

This time when we do a diff it will launch Meld with the right
parameters and we will see our visual diff.
//////////////////////////////////////////////////////////////////
git config --list

git in /usr/local/other/Git/1.6.6_GNU.

You need to put /usr/local/other/Git/1.6.6_GNU/bin in your path.
Also you will need to add
/usr/local/other/curl/7.19.6 and its bin directory to your path.
You will need to set environment variable
GIT_EXEC_PATH equal to /usr/local/other/Git/1.6.6_GNU/libexec/git-core.
Please add /usr/local/other/curl/7.19.6/lib to your library path.
The command
git clone http://esg-repo.llnl.gov/git/cmor.git
should work, creating directory cmor.


git config --global user.name "Nick Tausnev"
git config --global user.email "ntausnev@giss.nasa.gov"
git config --global color.ui "auto"
git config --global merge.tool vimdiff

//////////////////////////////////////////////////////////////////
1,
We saw that the ls command, used for listing directory contents, is an
alias. Aliases are a handy way to configure some commands to use
different sets of defaults or to provide an alternate name for a
command. In our example, the --color=tty option causes directory
listings to be color coded according to the type of file or directory.
Try running dircolors --print-database to see how the color codings are
controlled and which colors are used for what kind of file.

2
The ls colors  are controlled by the dircolors command.  First, dump
the current settings to a file using dircolors:

# dircolors --print-database > ~/.dircolors

Then edit the file ~/.dircolors.  This contains all the current
settings.

Now edit the ~/.dircolors file.  The color you probably want to change
is "file".  It's  set to 00 (probably white).  I use 01 (bright white)
for that.  You can specify a background color too, with xx;xx.  The
.dircolors file will have instructions in it.

Save the file after editing it.  To activate your changes, run dircolors
like so:

# eval `dircolors ~/.dircolors`

And then you should have the new colors.  Add this line to your .profile
if you want these changes every time you log in.

The next step is to edit the file ~/dircolors.txt. This file.s format is
easy to understand and self-documented; I had no problem finding the
file that begins with .DIR. and change the color to my taste.

Next, I try out the new color scheme:

After finding the color scheme I liked, I saved it to my start up file:

    dircolors -b ~/dircolors >> ~/.profile

//////////////////////////////////////////////////////////////////
Compare rundecks:
 /discover/nobackup/projects/giss/exec/get_objmod_infile_parm_lists EhBio.R

//////////////////////////////////////////////////////////////////
But then much longer, and possibly nested.  Position the cursor on the
"#ifdef" and press %.  Vim will jump to the "#else".  Pressing % again takes
you to the "#endif".  Another % takes you to the "#ifdef" again.
   When the construct is nested, Vim will find the matching items.  This is a
good way to check if you didn't forget an "#endif".
   When you are somewhere inside a "#if" - "#endif", you can jump to the start
of it with:

    [#

If you are not after a "#if" or "#ifdef" Vim will beep.  To jump forward to
the next "#else" or "#endif" use:

    ]#

These two commands skip any "#if" - "#endif" blocks that they encounter.
Example:

    #if defined(HAS_INC_H)
        a = a + inc();
    # ifdef USE_THEME
        a += 3;
    # endif
        set_width(a);

With the cursor in the last line, "[#" moves to the first line.  The "#ifdef"
- "#endif" block in the middle is skipped.

//////////////////////////////////////////////////////////////////
vim diffchanges
:colorscheme tabula
:syntax off

see all colors on vi :SCROLL

or:
:SelectColorS
:EditCurrentColorS

//////////////////////////////////////////////////////////////////
#!/bin/ksh
# tested with ksh93s+

builtin printf

integer a=0
integer b=0

read a?"Enter value of a: " || { print -u2 "Input of a aborted." ; exit 1 ; }
read b?"Enter value of b: " || { print -u2 "Input of b aborted." ; exit 1 ; }

if (( a < b )) ; then
    printf "%d is less than %d\n" a b
fi
if (( a == b )) ; then
    printf "%d is equal to %d\n" a b
fi
if (( a > b )) ; then
    printf "%d is greater than %d\n" a b
fi

exit 0
//////////////////////////////////////////////////////////////////
For example rename all *.bak file as *.txt, enter:
$ rename .bak .txt *.bak

To remove .jpg file extension, you write command as follows:
$ rename 's/\.jpg$//' *.jpg

rename 'ANN2420-2439' 'ANN2481-2500' *.nc *.PRT


//////////////////////////////////////////////////////////////////
PN=${0##*/};  print $PN # Program name
//////////////////////////////////////////////////////////////////
Instalation CMOR
./configure --prefix=/discover/nobackup/klo/CMOR2
--with-netcdf=/usr/local/other/netcdf/4.0.1_gnu
--with-hdf5=/usr/local/other/hdf5/1.8.3_serialGNU
--with-udunits2=/usr/local/other/udunits/2.0.3_intel-10.1.021
--with-uuid=/usr/local/other/uuid/1.6.2

//////////////////////////////////////////////////////////////////

Extracting a range of pages from a PDF, using GhostScript
See also: https://www.commandlinefu.com/commands/using/gs

gs -sDEVICE=pdfwrite -dNOPAUSE -dBATCH -dSAFER -dFirstPage=14 -dLastPage=17 \
   -sOutputFile=OUTPUT.pdf ORIGINAL.pdf

Joining PDFs the Ghostscript way:

gs -dBATCH -dNOPAUSE -q -sDEVICE=pdfwrite -sOutputFile=result.pdf \
gmeta_p40-p40.pdf gmeta_p81-p81.pdf gmeta_p93-p93.pdf             \
gmeta_p114-p114.pdf gmeta_p255-p255.pdf

You have a lot of ps files and you want to combine them into a single
pdf file with multiple pages:
gs -q -sPAPERSIZE=letter -dNOPAUSE -dBATCH -sDEVICE=pdfwrite -sOutputFile=out.pdf z1.ps z2.ps z3.ps

How do I convert a PS file in.ps into a PDF file?
ps2pdf in.ps
gives a PDF file in.pdf.

I have a PS file in.ps with 234 pages from which I want to extract the pages 3,4,7,20 ?
  pstops 1000:3,4,7,20 in.ps>out.ps
generates a file out.ps containing all pages which are 3,4,7,20 modulo 1000.
//////////////////////////////////////////////////////////////////
Merge Postscript files
To merge (join, combine, etc.) multiple Postscript files into a single
one, just type this:

gs -sDEVICE=pswrite -sOutputFile=output.ps -dNOPAUSE \
   -dBATCH file1.ps file2.ps file3.ps

//////////////////////////////////////////////////////////////////
diffchanges.vim : Show changes made to current buffer since the last
save
\dcd ---> DiffChangesDiffToggle - toggles the side-by-side diff view
\dcp ---> DiffChangesPatchToggle- toggles the patch view
//////////////////////////////////////////////////////////////////
Here Document ksh

Syntax:

command << label
input line 1
.
input line n
label

This allows you to redirect input to a shell script from within the shell script itself.

    * << label indicates that label marks the end of the here document
    * label must appear on a line by itself to end the here document
    * << 'label' prevents the shell from doing parameter and command substitution in the here document
    * <<- label deletes leading tabs (but not spaces) from the here document

Here Document Example
(from page 189 in "Learning the Korn Shell")

pgmname=$1
for user in $(ypcat passwd | cut -f1 -d:)
do
  mail $user <<- EOF
  Dear user,
  A new version of $pgmname has been installed
  in $(whence $pgmname).
  Regards,
  Your friendly sysadmin
EOF
done

$ cat <<-!
     This is a demonstration of a here document. As you can see the
     document uses the operator << to tell the shell that all the text on the next
     line to the label, in this case is !, is all to be read in and redirected to
     the cat command. This - tells the shell to remove leading tabs at the start
     of the line.
!


//////////////////////////////////////////////////////////////////
Python:

onvert program from python version 2 to version 3

/discover/nobackup/ntausnev/PYTHON/bin/2to3 --help
/discover/nobackup/ntausnev/PYTHON/bin/2to3 -w example_p2.py
//////////////////////////////////////////////////////////////////
In the following example, corresponding lines from three different
files are combined and shown appropriately.

$ cat emp-number.txt
100
200
300
400
500

$ cat emp-firstname.txt
Emma
Alex
Madison
Sanjay
Nisha

$ cat emp-lastname.txt
Thomas
Jason
Randy
Gupta
Singh

$ paste emp-number.txt emp-firstname.txt emp-lastname.txt
100     Emma    Thomas
200     Alex    Jason
300     Madison Randy
400     Sanjay  Gupta
500     Nisha   Singh

//////////////////////////////////////////////////////////////////
FERRET:
we can use DEFINE ATTRIBUTE to redefine an existing attribute or SET
ATTRIBUTE and CANCEL ATTRIBUTE to change settings or values of an
attribute.

yes?  SHOW ATT/ALL ARRAY
yes?  DEFINE ATT ARRAY.valid_min  = -1.000000E+30
yes?  DEFINE ATT ARRAY._FillValue = -1.000000E+30
yes?  SHOW ATT/ALL ARRAY

yes?  shade/lev=(-inf)(0,4,0.1)(inf) ARRAY

yes? shade/lev=(0,5.0,0.1)(5.,50.,5.)(inf) ARRAY

     shade/l=3/lev=(-2.5,38,0.20)/PALETTE=ocean_temp sst


//////////////////////////////////////////////////////////////////
CDAT:
export LD_LIBRARY_PATH=/usr/local/other/CDAT/5.1.0_gnu/Externals/lib:/usr/local/other/CDAT/5.1.0_gnu/lib; vcdat
//////////////////////////////////////////////////////////////////
Change background color in VIM
:highlight Normal ctermbg=DarkGreen
//////////////////////////////////////////////////////////////////
Intel cpp:
ifort -fpp -DTRACERS_GASEXCH_ocean -P -o zOut.f zIn.F
-save-temps this option tells the compiler to save intermediate
files created during compilation. The names of the files saved
are based on the name of the source file; the files are saved
in the current working directory.

If option -save-temps is specified, the following occurs:
The object .o file (Linux OS and OS X) or .obj file (Windows OS) is saved.
The assembler .s file (Linux OS and OS X) or .asm file (Windows OS)
is saved if you specified the use-asm option.

The .i or .i90 file is saved if the fpp preprocessor is invoked.

//////////////////////////////////////////////////////////////////

To run lynx with the url file:/usr/local/, type:
$ xterm -e lynx file:/usr/local/ ..RETo
In this example, lynx opens the given url in its own window, and will
remain until you either kill the window or exit lynx.
//////////////////////////////////////////////////////////////////
Information about pbs queues:
qstat -Qf test
qstat -q   # quiet
qstat -f   # full
//////////////////////////////////////////////////////////////////
NCCS directory with ferret, GrADS, meld
/usr/local/other
//////////////////////////////////////////////////////////////////
COLOR prompt ksh
PS1=$'\E[46;31m'`logname`@$'\E[1;33m'`hostname -s`:$'\E[0m>'
PS1=$'\E[46;31m'`logname`@$'\E[1;33m'`hostname -s`:$'\E[0m -> '

change text colors

You can change the color of text in an xterm.
This can come in handy it you're writing shell scripts. Try this example:

echo -e "\033[42;1m Pretty colors \033"
//////////////////////////////////////////////////////////////////
# Use ack to search my history file; pipe to less if necessary
hack()
{
    var=$(history | ack $1 | wc -l)
    if (( $var > 22 ))
    then
        history | ack $1 | less
    else
        history | ack $1
    fi

}

//////////////////////////////////////////////////////////////////
Prune a set of empty directories

function prunedir () {
   find $* -type d -empty -print0 | xargs -0r rmdir -p ;
}

Use with some caution!

//////////////////////////////////////////////////////////////////
Get file from www
curl http://ack.googlecode.com/svn/tags/latest/ack > ~/act
//////////////////////////////////////////////////////////////////
ijprt fileName recordNumber [ scalar offset]
lprt6 print on poncho
//////////////////////////////////////////////////////////////////
xfontsel - point and click selection of X11 font names
//////////////////////////////////////////////////////////////////
enscript
enscript -pzModelE.ps \
-fTimes-Roman12  \
--underlay="Hello, world!" --ul-gray=0.95  --ul-style=filled \
--fancy=a2ps \
--borders  \
/home/ntausnev/ACC_UTILS/get_avr_acc_months.pl; gv zModelE.ps


enscript --quiet --no-header --font=Courier-Bold@8/8 --truncate-lines
--landscape --margins=25:25:40:40 -p - ${i}
//////////////////////////////////////////////////////////////////
Remove comments before ifdef options in rundecks
Something is doing with DOMAIN_DECOMP.f

OpenMPI & INTEL10 compiler:
module purge
module load  comp/intel-10.1.017
module load  mpi/openmpi-1.2.5/intel-10

gmake clean_all MODELERC="/home/ntausnev/.modelErc_openMPI_i10"
gmake depend RUN=E1i10 MODELERC="/home/ntausnev/.modelErc_openMPI_i10"
gmake -j6 setup RUN=E1i10 MODELERC="/home/ntausnev/.modelErc_openMPI_i10"

//////////////////////////////////////////////////////////////////
OpenMPI
gmake setup RUN=E1ia2  EXTRA_FFLAGS="-DMPITYPE_LOOKUP_HACK"  \
      MODELERC="/home/ntausnev/.modelErc_openMPI"
//////////////////////////////////////////////////////////////////
This command will recursively delete all the CVS files into
the current directory:

  find . -depth -name "RS*"  -exec rm -rf '{}' \; -print
  find . -depth -name 'CVS' -exec rm -rf '{}' \; -print

Recursively delete files matching pattern (or perform other action)
      # first deletes content of folder
      find . -name .svn -exec rm -rf {} \;

      #delete folders
      find . -name .svn -exec rmdir {} \;

find . -name *.exe | xargs /bin/rm -f

find . -type d -name "ABC" -print


find . -name "*.exe" -print -exec ls -l {} \; > z_exe


//////////////////////////////////////////////////////////////////
On Linux, compiling a LaTeX file is as simple as

  latex  file.tex  // compile
  tex    file.tex  // compile



  xdvi file  // the standard guesses the extension for viewing
  dvipdf  file  // make it a pdf from the dvi
  pdflatex  file.tex  // compile directly to pdf
  pdftex    file.tex  // compile directly to pdf

  xpdf abc.pdf

//////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////
filename=/tmp/var/proggram.cc
b=`basename $filename`
prefix=`echo $b | cut -d. -f 1`
suffix=`echo $b | cut -d. -f 2`

SUFFIX=${FILE#*.} # part after the first .
SUFFIX=${FILE##*.} # part after the last .

Delete suffix:  ${string%.*}
  string=abc.xyz; print ${string%.*}
  abc.xyz ===> abc

basename replacement:
---------------------

fullfile="/some/dir/file.txt"
# replaced: file=$(basename $fullfile)
 file=${fullfile##*/}
 echo $file
file.txt

dirname replacement:
--------------------

 fullfile="/some/dir/file.txt"
# replaced: dir=$(dirname $fullfile)
 dir=${fullfile%/*}
 echo $dir
/some/dir

//////////////////////////////////////////////////////////////////
How to remove new line char from a string
echo $string1 | tr "\n" " "
would change a new-line into a space
Reply With Quote

//////////////////////////////////////////////////////////////////
Delete lines n1-n2 from file
perl -nle 'print unless n1 .. n2' input

Use ls -l to get the list of files you want to sum and pipe
the result to a perl one-liner that sums the fifth column of
every line it processes.
For example, to get the total size of all your .rpm files
 in your current directory, use the following:
ls -l *rpm | perl -lane '$total += $F[4]; END { print "Total: $total bytes\n" }'

For example, insert the line "New line added!!" in line 100 of example.txt:
perl -pi -le 'print "New line added!!" if $. == 100' example.txt

If you want to insert the same line in multiple files, use the
following:
perl -pi -le 'print "New line added!!" if $. == 100; close ARGV if eof' *.txt
('close ARGV if eof' is needed to reset the variable '$.' before
processing the next file).

To sum numbers on a stream, where each number appears on a line by
itself. That kind of output is what you get from cut(1), if you cut out
a numerical field from an output.
perl -ne '$n += $_; print $n if eof'
perl5 -ne '$n += $_; END { print "$n\n" }'

    This piece will read paragraphs from the standard input and reformat
them in such a manner that every line is between 50 and 72 characters
wide. It will only break a line at a whitespace and not in the middle of
a word:
perl5 -p000e 'tr/ \t\n\r/ /;s/(.{50,72})\s/$1\n/g;$_.="\n"x2'

//////////////////////////////////////////////////////////////////
PSFTP & dirac
open dirac.gsfc.nasa.gov

//////////////////////////////////////////////////////////////////
Command-line Vim:
you can use Vim in a script non-interactively. For example:
vim -c "s/hello/goodbye cruel/" -c "wq" fun.txt

To yank an entire file into X11s clipboard:
gg"*yG
"*y

//////////////////////////////////////////////////////////////////
To remove .jpg file extension, you write command as follows:
$ rename 's/\.jpg$//' *.jpg

 To convert all uppercase filenames to lowercase:
$ rename 'y/A-Z/a-z/' *

//////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////
See what processors you have
more /proc/cpuinfo
//////////////////////////////////////////////////////////////////
Setup modelE
make -j setup RUN=xxx EXTRA_FFLAGS="-g -I/opt/scali/include64" ESMF=YES NPES=4

make setup RUN=xxx MODELERC="/home/ntausnev/.modelErc_serial"
//////////////////////////////////////////////////////////////////
Colors and fonts for GVIM
color spring

The Procedure
The process of permanently changing your gvim font can be broken down like this:

    * Use the menu to find a suitable font
    * Use set gfn? to find the text of that font
    * Copy the font text into .gvimrc
    * Backslash the spaces

See file gvimrc

//////////////////////////////////////////////////////////////////
Rainer Bleck graphics for HYCOM
/home/ntausnev/RB_MXD ( ~bleck/2.0deg/hycom/proc )

See file runscript and edit filename
csh runscript
=====> get file gmeta
See =====> idt gmeta
Conver in ps file :: ctrans -d ps.color gmeta > gmeta.ps

Rainer has file .ncarv_spool

cat ~/.ncarv_spool
mono_to_gmeta.ps : -d ps.mono -f font4 : > ./gmeta.ps
ps.color_to_gmeta.clr.ps : -d ps.color -f font4 : > ./gmeta.clr.ps

THIS IS LET YOU posibility to print from idt utility

//////////////////////////////////////////////////////////////////
Ferret6.1 on Discover
RedHat
mkdir /discover/nobackup/ntausnev/ferret_rh
export FER_DIR=/discover/nobackup/ntausnev/ferret_rh
export GET_LOCATION=/discover/nobackup/ntausnev/ferret_rh
export FER_DSETS=/discover/nobackup/ntausnev/ferret_rh/fer_dsets


 cd $FER_DIR
 zcat $GET_LOCATION/fer_environment.tar.Z | tar xvf -
 mkdir fer_dsets
 cd fer_dsets
 zcat $GET_LOCATION/fer_dsets.tar.Z | tar xvf -

 cd ../bin


//////////////////////////////////////////////////////////////////
 xterm -geometry 90x25 -sb -sl 1000 -title discover06 -fg White -bg
Gray60 -cr Black
//////////////////////////////////////////////////////////////////
Version 5.8 of ctags is installed in /usr/local/other/ctags/5.8.
The executable ctags is in /usr/local/other/ctags/5.8/bin directory.


Running "ctags --list-kinds" lists the kinds of information that can
be output for different languages.
/usr/local/other/ctags/5.8/bin/ctags -V --language-force=Fortran --fortran-kinds=+s *.F90 *.h *.inc


Recursive:
ctags --file-scope=no -R *

08/03/08 Installation ctags version 5.7
cd ctags-5.7/
./configure --prefix /discover/nobackup/ntausnev/ctags-5.7
 make
make install
./ctags  --version

spf13 vim the tagbar toggle is <Leader>tt, and the leader key is , by default.
//////////////////////////////////////////////////////////////////
/home/ssun/ssun/proc/hycom2degrfn last directory, readme.
/home/ssun/ssun/proc/hycom2degrfn/hist2ov
//////////////////////////////////////////////////////////////////
Does it have the ability to also save
tabs that you have opened with command ':tabnew'.
:mksession mysession
will save your session

:source mysession
or
:runtime mysession
will restore it

(look in the help : h mksession)
//////////////////////////////////////////////////////////////////
Totalview with intelMPI:
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
10/26/2010:

xsub -V -I -l select=2:ncpus=8:proc=harp,walltime=12:00:00 -W group_list=a940a /usr/bin/ksh
cat $PBS_NODEFILE
#Make sure you have loaded module tool/tview-8.7.0.7.

export TVDSVRLAUNCHCMD=ssh

export TOTALVIEW=/usr/local/toolworks/totalview.8.7.0-7/bin/totalview

mpdboot -r ssh -n 2 -f $PBS_NODEFILE

mpdtrace

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

export TVDSVRLAUNCHCMD=ssh

export number_nodes=2; \
xsub -I -V -W group_list=a940a -q general_small \
     -l nodes=${number_nodes}:ppn=8,walltime=12:00:00 /usr/bin/ksh
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

# TOTALVIEW will need:

export TVDSVRLAUNCHCMD=ssh
export number_nodes=2; \
xsub -I -V -W group_list=a940a -q general_small \
     -l nodes=${number_nodes}:ppn=8,walltime=12:00:00 /usr/bin/ksh

module purge
module load comp/intel-10.1.017
module load mpi/impi-3.2.011
module load tool/tview-8.6.2.2
module list

export number_nodes=2; \
mpdboot -r ssh -n ${number_nodes} -f $PBS_NODEFILE

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  mpiifort -g -traceback sources

mpdboot -r ssh -n <num_nodes> -f $PBS_NODEFILE
mpiexec -tv -n <number-of-processes> ./<path-to-your-executable>

06/11/2010:
Totalview with Intel MPI on the Discover system.
Give these instructions a shot:

   1. On your local machine, issue this command to get onto Discover:
      ssh -Y login.nccs.nasa.gov
      This forwards any X windows from Discover to your local machine.

   2. Establish an interactive session, with X11 forwarding, by this command:

      xsub -I -l select=2:ncpus=8,walltime=4:00:00 -W group_list=a940a

      The above example asks for two nodes and eight CPUs per node.
      It also asks for a wall time of 4 hours.
      Replace GROUPNAME with your Sponsor Code if you know it.
      You can also find this in the first column of output from the "getsponsor" command.

   3. Once you're in your interactive session, load any compiler/Intel MPI
      library/Totalview combination you wish. Here's an example:
            comp/intel-11.1.056
            mpi/impi-3.2.2.006
            tool/tview-8.7.0.7

      IMPORTANT NOTE:  with the Intel 11 compiler on Discover,
      you MUST use this module:  tool/tview-8.7.0.7.
      The older Totalview modules can be used with Intel compilers 10 and older.

   4. Build your application with the "-g -traceback" flags to
      enable source-level debugging functionality.

   5. Ensure that the following environment variable is set; it allows Totalview
      to debug processes located on other nodes:

      TVDSVRLAUNCHCMD=ssh

   6. Issue the following command to launch Totalview:

      mpdboot -r ssh -n <num_nodes> -f $PBS_NODEFILE
      totalview <path-to-your-executable>

      Please note that num_nodes is the number you have set "select"
      to in your "xsub"  command.
      Also please note that the path to your executable can be absolute or relative,
      but it cannot simply be the name of your executable.

   7. In the dialog that appears, entitled "Startup Parameters - myprog.x",
      go to the "Parallel" tab and from the "Parallel System" drop-down menu select "Intel MPI".
      For "Tasks", enter the number of MPI processes you'd like to run with, and for "Nodes"
      enter the number of nodes you'd like to use.  Select "OK" when finished.

   8. The code from your application should now be visible in the main window.
      Set breakpoints as you wish, and begin the run.


Totalview on discover:
export TVDSVRLAUNCHCMD=ssh
xsub -V -I -l select=1:ncpus=4,walltime=01:00:00 -W group_list=a940a /usr/bin/ksh
mpirun -tv -inherit_limits -np 4  ./t_mpi.exe
//////////////////////////////////////////////////////////////////
Go discover from palm:
ssh -Y discover
//////////////////////////////////////////////////////////////////
Sort lines in vim using blocks:
:<range>!sort
Yes, its that simple.

Key strokes:
1) Place cursor at first line of range to be sorted.
2) Use marker (ma) to mark starting point
3) Go to last line of range to be sorted
4) Issue command from marker (a) to here as follows:
:'a,.!sort
Hope this little reminder helps.
//////////////////////////////////////////////////////////////////
FULL information about batch job:
qstat -f 767024.borgmg | more
//////////////////////////////////////////////////////////////////
NCO on discover
the new installation:  /usr/local/other/NCO/3.9.5_intel9.1.052
//////////////////////////////////////////////////////////////////
To print an array with one element per line, you
could tack a newline character onto the end of each value like this:

    print map { "$_ \n" } @array;

One by one, each element of the array is assigned to the default
variable $_  and is quoted with a newline character: "$_\n". By the time
all the elements are done, map has a copy of the original array but with
a newline added to each element. It returns that new list. The print
statement then prints the new list, and each orignal array value comes
out on its own line.
//////////////////////////////////////////////////////////////////
We also often need to know not only if there is match or not,
 but also what is the substring that matches the pattern.
 Perl provides several special variables for that purpose:

    * $& - contains the matching substring
    * $` - contains the substring on the left of the match
    * $' - contains the substring on the right of the match

Let's modify the previous example:

$str = "My phone number is 123-3445. This is my home phone.";
if( $str =~ /\d{3}-\d{4}/ ){
   print "There is a phone number in the string '$str'\n";
   print "The phone is: $&\n";
   print "      Before: '$`'\n";
   print "       After: '$''\n";
}
else{
   print "There is not a phone number in the string '$str'\n";
}

//////////////////////////////////////////////////////////////////
Print post script files from athena/poncho:
 lp -dpub7 hycom_msf.ps

 lpr -Ppub7duplex file.ps

Status printers on Poncho:
 lpstat -a
//////////////////////////////////////////////////////////////////
The limit command displays the current main stack size as well as sets
it:
ulimit -a

//////////////////////////////////////////////////////////////////
Here is new Bat installation:
/discover/nobackup/mbhat/Esmf222rp3/esmf/

here is his test:
/discover/nobackup/mbhat/Esmf222rp3/esmf/
//////////////////////////////////////////////////////////////////
export ESMF_DIR=/discover/nobackup/ntausnev/esmf; \
export ESMF_INSTALL_PREFIX=/discover/nobackup/ntausnev/esmf/../esmf_9.1.042; \
export export ESMF_EXHAUSTIVE=ON; \
export ESMF_BOPT=g; export ESMF_COMM=mpi; export ESMF_COMPILER=intel;\
export ESMF_ABI=64; unset   MPI_HOME;

//////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////
MPI-2:
export SCAMPI_ALLOW_DEPRECATED=0; export SCAMPI_DEPRECATED_BOTTOM=0
export SCAMPI_WORKING_DIRECTORY=/discover/nobackup/ntausnev/ALAN_01/RUN
http://www.grycap.upv.es/usuario/doc/ScaMPI_Faq.pdf

//////////////////////////////////////////////////////////////////
How can I pick colors visually?
Another approach is to use a standard tool in the Tk system:

% echo 'tk_chooseColor ; exit' | wish

That gives you slider bars for selecting the red, green, and blue
intensities, showing the resulting mixture in a colored box.
Unfortunately, the RGB color model is hard for humans to manipulate, so
it can be difficult to find the right combination of primary colors to
produce the color blend that you want, and you'll have to do the
conversion to hexadecimal yourself for the X Window System.

On other systems, for now, you may have to resort to guessing, possibly
by tweaking intensity levels of named colors that are close to what you
want.


//////////////////////////////////////////////////////////////////
Sort lines - easy use of existing vim capability
export LC_ALL=C # to get the traditional sort order

:%!sort
:'a,'b!sort

//////////////////////////////////////////////////////////////////
Insert the template fortran90 subroutine
:r !~/MySysDir/Templates/subf90.ksh nameSubroutine
//////////////////////////////////////////////////////////////////
totalview with MPI on Discover:

export TVDSVRLAUNCHCMD=ssh
export DISPLAY=localhost:24.0
ssh -X totalview
. ${MODULESHOME}/init/ksh
module load   comp/intel-9.1.042
module load   lib/mkl-9.0.017
module load   mpi/scali-5.3
module load   tool/tview-8.0.0.0

ntausnev@discover01:/home/ntausnev> module list
Currently Loaded Modulefiles:
 1) comp/intel-9.1.042   2) lib/mkl-9.0.017  3) mpi/scali-5.3   4)
tool/tview-8.0.0.0

export TVDSVRLAUNCHCMD=ssh; ssh -X totalview;
qsub -I -V -W group_list=a940a -l select=1:ncpus=4,walltime=12:00:00

cd /gpfsm/dhome/ntausnev/MPI_TEST/OBJECTS_poisson_clt


mpirun -tv -np 7 poisson.exe
I see the two totalview windows.
Click GO

//////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////
command
 cat file.txt |sed -e '1,10s/a/A/g'
 replaces all 'a' with 'A' from 1 to 10 line
//////////////////////////////////////////////////////////////////
Install AAP
./aap install PREFIX=/discover/nobackup/ntausnev/AAP
//////////////////////////////////////////////////////////////////
Simple regular expression substitution
To change or substitute the text FROMX to TOX, use sed. You can specify regular expressions for FROMX. A

  sed -e "s/FROMX/TOX/"     # subst first occurrence
  sed -e "s/FROMX/TOX/g"        # subst all occurrences
    # strip off domain name (remove .in20pages.com)
  echo "speedster.in20pages.com" | sed -e "s/[.].*$//"
    # keep domain name (remove speedster.)
  echo "speedster.in20pages.com" | sed -e "s/^[^.]*[.]//"

Delete exessive  spaces/blanks from string:
    print " a b  c   d " | sed "s/^ *//;s/ *$//;s/ \{1,\}/ /g"

This piece will remove spaces at the beginning and end of a line and
squeeze all other sequences of spaces into one single space.
perl -pe '$_ = " $_ "; tr/ \t/ /s; $_ = substr($_,1,-1)'

    This piece will read paragraphs from the standard input and reformat
them in such a manner that every line is between 50 and 72 characters
wide. It will only break a line at a whitespace and not in the middle of
a word.
perl5 -p000e 'tr/ \t\n\r/ /;s/(.{50,72})\s/$1\n/g;$_.="\n"x2'
//////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////
extract from file string with ' something' and print in separate
lines
awk -F "'" '{ for (f=1; f<=(NF-1)/2; f++) print $(f*2) }' input_text

it's simple to execute the Awk program from a shell script.
 For example, consider an Awk script to print each word
in a file on a separate line.
This could be done with a script named "words" containing:
   awk '{c=split($0, s); for(n=1; n<=c; ++n) print s[n] }' $1

Join a line ending with a backslash with the next line (only one time):
awk '/\\$/ { sub(/\\$/,""); getline t; print $0 t; next }; 1'

Delete the second field on each line.
awk '{ $2 = ""; print }'
This one liner just assigns empty string to the second field. It.s gone.

Awk : print certain column ranges
Assume a default file delimited by whitespace;
start at column 4 and print each column to the end.
Print a CR at the end of each line:

#!/bin/ksh
awk ' {
for (i=4; i<=NF; i++)
printf("%s ", $i)
printf("\n") # CR at end of line
} ' mydatafile

Is there an easy way to print out the last 4 columns
or rather the 4th and 3rd last column?
How about: awk '{print $(NF-3), $(NF-2)}'

To extract the K-th, M-th and P-th words
It is better to use awk (or gawk or nawk) because awk handles words separate
by spaces and tabs correctly. The cut program (as of 2001) is quite stupid
and assumes precisely one space between words.

  awk '{ print $K, $M, $P; }'

$ echo " abc ddd xxxx" | awk '{ print $3,$1}'
xxxx abc

$ echo " abc ddd xxxx" | awk '{ print $3 " - " $2}'
xxxx - ddd

Print columns from 5 to 9
awk '{for(i=5;i<=9;i++)printf "%s ",$i;print ""}' filename

Print columns from 5 to last column
awk '{for(i=5;i<=NF;i++)printf "%s ",$i;print ""}' filename

Here's a simple one-line script that will print out the fourth word of
every line, but also skip any line beginning with a # because it's a
comment line.

    perl -naF 'next if /^#/; print "$F[3]\n"'

Here is example on how to print first and the second from the last
columns:

     perl -lane 'print "$F[0]:$F[-2]\n"'

//////////////////////////////////////////////////////////////////
Subject: Summary: get the last line in a file that matches a pattern

The concensus seems to be just grep the patters from
the file and pipe it out to tail -1. I was hoping for
something fancier, but this will work...

also had this nice awk command:
awk '/<your date pattern>/{last=$0} END{print last}' <your file>


//////////////////////////////////////////////////////////////////
#CVS on Dirac:
cvs -d $ARCHIVE/CVS_TNL init    # Dirac

#on Discover/palm import into CVS
CVS_SERVER=/usr/bin/cvs cvs -d dirac:$ARCHIVE/CVS_TNL \
import -m "Imported sources and sub directories" nameDirInCVS nick start


#on Discover/palm get a working copy from CVS
CVS_SERVER=/usr/freeware/bin/cvs cvs -d dirac:$ARCHIVE/CVS_TNL \
checkout -d z_newNameDir nameDirInCVS


//////////////////////////////////////////////////////////////////
Reto rundeck
 E1oM20.R
Larissa rundeck:
/discover/nobackup/larissa/E13/decks/E13BoM20.R
Larissa rundeck for 2.5 grid
/discover/nobackup/larissa/Gary_Changes/modelE2/decks/E2F40o13.R # 2x2.5
/discover/nobackup/larissa/Gary_Changes/modelE2/decks/E1M20o13.R # 4x5
no ocean:
/discover/nobackup/larissa/E13/decks/E13BM20.R
Shan Sun rundeck:
/gpfsm/dnb1/ssun/modelE/model/ha_feb07/E3a20t0.R
//////////////////////////////////////////////////////////////////
print each word on its own line
cat file | awk '{ for ( i = 1; i <= NF; i++ ) print $i}' | sort

more z_srcs | perl -pe 'tr/[ \t]/\n/s' | more

//////////////////////////////////////////////////////////////////
fcop file_in file_out skip now_many_take 0
//////////////////////////////////////////////////////////////////
Reto stuff for discover:
/discovery/nobackup/projects/giss/exec
//////////////////////////////////////////////////////////////////
modelE on Discover:
gmake setup RUN=??? MP=NO ESMF=NO
NETCDFHOME=/usr/local/other/netcdf/3.6.1 COMPILE_WITH_TRAPS=YES \
  EXTRA_FFLAGS=-mp EXTRA_LFLAGS=-mp

//////////////////////////////////////////////////////////////////
Shift FORTRAN-90 comments after get_nice_f90:
:/g/^\s*!/s//!/g
//////////////////////////////////////////////////////////////////
Copy files from or to Discover
FROM Palm to discover (you are on Discover)
scp palm.nccs.nasa.gov:/absPathFilePalm FileNameDisc
FROM Discover to Palm (you are on Discover)
scp FileNameDisc palm.nccs.nasa.gov:/absPathFilePalm
//////////////////////////////////////////////////////////////////
How do I reduce a range of blank lines to a single blank line?
In ex mode:

v/./.,/./-1join
//////////////////////////////////////////////////////////////////
Set the shell variables bold, to begin stand-out mode
sequence,  and  offbold,  to  end
standout  mode sequence, for the current terminal.  This
might be followed by a prompt:
echo "${bold}Please type in your name: ${offbold}\c"
$ echo "${bold}Please type in your name: ${offbold} first, last"

Try (light)
export bold=`tput smso`; export offbold=`tput rmso`
$ echo "${bold}Please type in your name: ${offbold} first, last"



//////////////////////////////////////////////////////////////////
Examples:
  cmd 2>/dev/null
  cmd >/dev/null 2>&1
//////////////////////////////////////////////////////////////////
Prepend a string to each line of output from stderr and stdout for each
MPI process:

 mpirun -prefix "[%g] " -np 4 a.out
[0]  Starting task           0
[1]  Task:           1  MPI_RECV Calls:            1
[2]  Task:           2  MPI_SEND Calls:            1

mpirun  -p "|--%g of %G on %@--> "  -np 4 a.out
|--3 of 4 on palm-->  Starting task           3
|--0 of 4 on palm-->  Task:           0  MPI_SEND Calls:            1

with SCALI:
 mpirun -separate_output all  -np 5 hycom_asynchio_22

//////////////////////////////////////////////////////////////////
Piping the standard  and error  output of prog into tee, which is
piping it to prog.out and to stdout.
./prog 2>&1 | tee [-a] prog.out
my_command | tee -a /some/file > /some/other/file ===> output to two files
//////////////////////////////////////////////////////////////////
Automating FTP:
#!/bin/sh

ftp -n <<EOF
open www.selectorweb.com
user myname mypass
get sleep.pl
quit
EOF
Note: "-n" option prevents ftp from asking the login and passwd on open
command.
Thus you can supply them both using the user command.
Here is another way of doing the same plus some minimal error checking
#!/bin/sh

echo "open webprod
      user login passwd
      verbose
      cd dir1/dir2
      bin
      get file1.cgi
      close
      quit" | ftp -n > myftplog

# Check FTP log to see if the file was retrieved okay

if grep "^226" myftplog
then
  echo "Successfully got the file from remote server" >> myftplog
else
  echo "Failed to get the file" >> myftplog
fi


//////////////////////////////////////////////////////////////////
cvs -d :pserver:anonymous@cvs.fms.sourceforge.net:/cvsroot/fms co -r havana coupled_example
//////////////////////////////////////////////////////////////////
 Grabbing Parts of a String:
last=`expr "$*" : '.* \(.*\)'`     # LAST ARGUMENT
first=`expr "$*" : '\(.*\) .*'`    # ALL BUT LAST ARGUMENT

Length string in ksh:
echo ${#string}

The following code fragment sets an array from the
command line arguments, counts the number of array elements,
and prints them

#! /usr/bin/ksh

# Set array "args" from command line arguments
set -A args -- "$@"

integer n=${#args[@]}   # number of array elements

print "$n arguments:"
integer i=0
while ((i<n))
do
   print ${args[i]}
  ((i=i+1))
done

# ksh loop:
max=1400
set file="afilename"
i=1

while (( i <= max ))
do
   # $(echo value of is : $i >> $file)
   echo value i: $i
   (( i += 1 ))
done

new ksh93 syntax:

integer i
for (( i=1; i<=10; i++ ))
do
   echo $i
done

//////////////////////////////////////////////////////////////////
To get a list of environment variables:
set
List of exported variables:
typeset -x
//////////////////////////////////////////////////////////////////
Internet (mozilla) on palm:
/bin/sh /usr/bin/mozilla
//////////////////////////////////////////////////////////////////
I am using Korn shell and using the following syntax to remove ctrl-M
characters.
   cat $input | sed "s/^M$//" > file1
in vi
   %s/^M//g

To get the ^M hold contrl key, press V then M
//////////////////////////////////////////////////////////////////
How I find the directories that are taking up the most space:
du -kxS /giss/ntausnev | sort -rn | head -20
//////////////////////////////////////////////////////////////////
SHORTHOST=`hostname | sed 's/\..*//'`; print $SHORTHOST
//////////////////////////////////////////////////////////////////
07.29.07
See added lines at files:
less name_file
Shift+F
//////////////////////////////////////////////////////////////////
07.03.06
export  NETCDF_INCLUDE="/local/LinuxIA64/netcdf/netcdf-3.6.0-p1/include";
export NETCDF_LIB="/local/LinuxIA64/netcdf/netcdf-3.6.0-p1/lib";
export ESMF_BOPT="g"; export ESMF_COMM="lam"; export ESMF_COMPILER="intel"; \
export ESMF_EXHAUSTIVE="ON"; export ESMF_PRES="64"; \
export ESMF_DIR="/home0/ntausnev/esmf"; \
gmake all

//////////////////////////////////////////////////////////////////
COMPILER intel-comp.9.1.038

  cp  /giss/ntausnev/modelE_hyb6/decks/E3ntHyb6o/pipe_mod.nml_slv \
      /giss/ntausnev/modelE_hyb6/decks/E3ntHyb6o/pipe_mod.nml;    \
   export runId=E3ntHyb6o; make setup RUN=${runId} MP=NO ESMF=NO COMPILER=Intel8 \
   NETCDFHOME=/home0/ntausnev/PALM/netcdf-3.6.0-p1 \
   EXTRA_FFLAGS="-Duse_netCDF " 1>z_setup_${runId} 2>&1 &

//////////////////////////////////////////////////////////////////
 cp  /giss/ntausnev/modelE_hyb6/decks/E3ntHyb6o/pipe_mod.nml_slv \
        /giss/ntausnev/modelE_hyb6/decks/E3ntHyb6o/pipe_mod.nml;        \
         export runId=E3ntHyb6o; make setup RUN=${runId} MP=NO ESMF=NO COMPILER=Intel8 \
         NETCDFHOME=/home0/ntausnev/PALM/netcdf-3.6.0-p1 \
        EXTRA_FFLAGS="-Duse_netCDF -I/home0/ntausnev/PALM/netcdf-3.6.0-p1/src/f90 \
        -I/home0/ntausnev/PALM/netcdf-3.6.0-p1/include " \
        EXTRA_LFLAGS="-L/home0/ntausnev/PALM/netcdf-3.6.0-p1/lib -lnetcdf" \
        1>z_setup_${runId} 2>&1 &


//////////////////////////////////////////////////////////////////
MODELE and NETCDF no MPI no OPENMP
cp  /giss/ntausnev/modelE_hyb6/decks/E3ntHyb6o/pipe_mod.nml_slv
/giss/ntausnev/modelE_hyb6/decks/E3ntHyb6o/pipe_mod.nml;
export runId=E3ntHyb6o; make setup RUN=${runId} MP=NO ESMF=NO COMPILER=Intel8
EXTRA_FFLAGS="-Duse_netCDF -I/home0/ntausnev/PALM/netcdf-3.6.0-p1/src/f90
-I/home0/ntausnev/PALM/netcdf-3.6.0-p1/include "
EXTRA_LFLAGS="-L/home0/ntausnev/PALM/netcdf-3.6.0-p1/lib -lnetcdf"
1>z_setup_${runId} 2>&1 &
//////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////
PRESCRIBE ocean setup:
export runId=E3ntPrc; make setup RUN=${runId} MP=NO ESMF=YES NPES=4 COMPILER=Intel8  \
 EXTRA_FFLAGS="-I/opt/sgi/mpt/1.12.0.0/include" ESMF_DIR=/giss/esmf_2_2_0rp1_Intel.9.0.024 \
 MPIDIR=/opt/sgi/mpt/1.12.0.0/ 1>z_setup_${runId} 2>&1 &
//////////////////////////////////////////////////////////////////
May 18, 2006
Checkout modelE from palm:
export CVSROOT=simplex.giss.nasa.gov:/giss/cvsroot; export CVS_RSH=ssh
cvs checkout modelE
checkout with new name:
cvs checkout  -d modelE_new_name modelE

cvs checkout -D "10 days ago"  -d modelE_ia modelE
cvs checkout -D '2010-08-01 12:00:01 GMT'  -d EhAug01 modelE

ONLY directory with source dir: cvs checkout -d model_cvs modelE/model

cvs checkout -r ModelE1-patches -d modelE1_patches_test modelE

To get the list of files between two dates using CVS:
cvs diff -N -c -D 2010-08-10 -D 2010-08-15 | grep "Index:" > diff.out

//////////////////////////////////////////////////////////////////
cmp -l file1 file2 | more
//////////////////////////////////////////////////////////////////
FERRET on DIRAC:
Ferret has been installed on dirac. In order to use Ferret, please login to
dirac and do the following:

% module load pd-ferret-5.7
export FER_DATA=". $FER_DSETS/data $FER_DIR/go $FER_DIR/examples $FER_DIR/contrib"
% ferret -gui
If you have any questions, please let me know.
Udaya
//////////////////////////////////////////////////////////////////
# USAGE: create pbs file for runId. Target get_pbs
 gmake -f /home0/ntausnev/PALM/MFILE_E/Makefile_my_modelE get_pbs  RUNID=
//////////////////////////////////////////////////////////////////
Interactive subshell for Palm:
qsub -I -l ncpus=08,walltime=12:00:00 -A "a940a" -q general_small /bin/ksh
//////////////////////////////////////////////////////////////////
make setup RUN=E3ntH2xc_navy MP=NO ESMF=YES NPES=2 COMPILER=Intel8 \
 EXTRA_FFLAGS="-DIA32 -DREAL8 -DMPI -DSERIAL_IO -DDEBUG_ALL -I/opt/sgi/mpt/1.12.0.0/include" \
 EXTRA_LFLAGS=" -L/opt/sgi/mpt/1.12.0.0/lib -lmpi -openmp " 1>z_setup_1 2>&1 &

AUXILIARY:
 make aux RUN=E3ntHyb3r MP=NO ESMF=YES NPES=2 COMPILER=Intel8 MPIDIR=/opt/sgi/mpt/1.12.0.0/
 make setup RUN=E001ia_tmp MP=NO ESMF=YES NPES=2 COMPILER=Intel8 \
 ESMF_DIR=/giss/esmf_2_2_0rp1_Intel.9.0.024 ESMF_BOPT=O \
 MPIDIR=/opt/sgi/mpt/1.12.0.0/
//////////////////////////////////////////////////////////////////
03/14/06
create a copy existing rundeck with new name
make rundeck RUN=E3ntNew RUNSRC=E3hyc01_hybrid OVERWRITE=YES

gmake rundeck RUN=<new RunID> RUNSRC=<RunID from templates>


//////////////////////////////////////////////////////////////////
03/10/06
export ESMF_COMM=mpi
export ESMF=YES; export OMP_NUM_THREADS=1; export NUM_THREADS_HYCOM=2; export MPI=2

export runId=E3ntHybXXX; make setup RUN=${runId} MP=NO ESMF=YES NPES=2 COMPILER=Intel8 \
  EXTRA_FFLAGS=" -I/opt/sgi/mpt/1.12.0.0/include" \
  EXTRA_LFLAGS=" -L/opt/sgi/mpt/1.12.0.0/lib -lmpi -openmp " 1>z_setup_${runId} 2>&1 &


//////////////////////////////////////////////////////////////////
02/02/06
ldd  prints  the  shared  libraries  required by each program or shared
     library specified on the command line.

//////////////////////////////////////////////////////////////////
Reverse the problem. Only print the line if it _doesn't_ match the regex.

  perl -ni~ -e 'print unless /pattern/' file
//////////////////////////////////////////////////////////////////
02/01/06
I want to do some in-place substitutions in a text file. In some
cases, I want to delete the whole line if it matches a certain
pattern.
An almost identical solution is:

  perl -pi~ -e '$_="" if /some-pattern/' file

Example: perl -pi~ -e '$_="" if /1845/' *E3ntHpalm2 # deletes
lines with 1845 from many lpl files.

//////////////////////////////////////////////////////////////////
Is one file newer than another

ls:
   newer() {        # is file 1 newer than all others given
      [ `ls -1rtd "$@" | tail -1` = "$1" ]
   }
   older() {        # is file 1 older than all others given
      [ `ls -1td "$@" | tail -1` = "$1" ]
   }
   # NOTE: the use of -r ensudes that ls is forced to reorder the files
   # to produce a true result. This ensures that if the files are the
   # same age (in which case ls don't bother re-ording) the result is always
   # false.

multiple ls:
 This is the best solution. ls can list a large collection of files
 in the right order. You can then if you want sed for newer or older files
 than a known filename (present or not)
   # Tom Christiansen ---  tchrist@convex.COM
   set `ls -td file1 file2`
   echo $1 is newer

//////////////////////////////////////////////////////////////////
Is a directory empty?

  # Anthony Thyssen -- my own solution - simple and obvious to script reader
  if [ -z "`ls -A $dir`" ];              # then empty

  # Jim Rogers -- 28790008@hplsdv7.hp.com   (compressed)
  if [ `ls -a $dir | wc -l` -eq 2 ];     # then  empty

//////////////////////////////////////////////////////////////////
How do I get a particular line or range of lines from a file?
   sed -n 300,350p foo.log

Using absolute Line numbers use
   front end         head -<number> file
   tail end          tail +<number> file
   single line       sed -n '<number>p;<number>q' file
   range of lines    sed -n '<from>,<to>p;<to>q' file

   NOTE: The `q' in the sed commands above is to avoid uneeded computer
   cycles, similarly for the exit in the nawk script below. Sed could also
   replace the head and tail commands, in a similar fashion, but is slower.

The problem with the above is if you want the lines relative to both
the start and the end of the file at the same time. "Sed" is a stream
editor but if you are dealing with a REAL file and not a pipe you can
also use "ed"

   All lines but last 15 lines     echo '1,$-15 p'   | ed -s file
   The 10th to the 5th last line   echo '$-10,$-5 p' | ed -s file

//////////////////////////////////////////////////////////////////
It was often frustrating when I would open a file deep in the code tree and
then realize I wanted to open another file in that same directory. Douglas
Potts taught me a nice way to do this. Add the following snipit to your
                  vimrc:

"   Edit another file in the same directory as the current file
"   uses expression to extract path from current file's path
"  (thanks Douglas Potts)
if has("unix")
   map ,e :e <C-R>=expand("%:p:h") . "/" <CR>
else
   map ,e :e <C-R>=expand("%:p:h") . "\" <CR>
endif

Then when you type ,e in normal mode you can use tab to complete to the file.
You can also expand this to allow for spitting, etc. Very very nice.

Sometimes it may also be useful to change to the file's directory.
map ,cd :cd %:p:h<CR>

//////////////////////////////////////////////////////////////////
The command "type" may be used to find out, which
commandthe shell executes.
$ type lrt
lrt is an alias for 'ls -la -rt'

//////////////////////////////////////////////////////////////////
December 1, 2005
Start new xterm:
xterm -bg green -cr red -fg black &
xterm -bg white -cr black -fg black &

Some example on Halem(steal) also works on palm (08.02.07):
/usr/bin/X11/xterm -fn 5x7 -geometry 256x30 -sb -sl 10000 -bg lightsteelblue -fg black
xterm -T PALM -bg black -fg yellow -geometry 100x50 -sb -sl 500

xterm -title ksh -geometry 80x24 -fg black -bg green -bd black -fn 12x24 -cr red -ms red +ah -e ksh &
xterm -title ksh -geometry 80x24 -fg black -bg green -bd white -fn 12x24 -cr red -ms red +ah -xrm 'xterm*pointerShape: X_cursor' -e ksh &
xterm -title ksh -geometry 80x24 -fg black -bg green -bd white -fn 12x24 -cr red -ms red +ah -xrm 'xterm*pointerShape: hand1' -e ksh &
xterm -title ksh -geometry 80x24 -fg black -bg green -bd white -fn 12x24 \
      -cr red -ms red +ah -xrm 'xterm*pointerShape: hand1' -e ksh &
 xterm -sb -bg palegreen -fg black -fn lucidasanstypewriter-bold-18 -n discover &
//////////////////////////////////////////////////////////////////
November 17, 2005
hostd=$(hostname);PS1='p: $PWD ' Prompt on Palm
hostd=$(hostname);PS1='d: $PWD ' # Prompt on Daley

//////////////////////////////////////////////////////////////////
July 26, 2005
Added two perl scripts add_exl and add_pnd
that insert the comment box for fortran and scrpt files in vi
In vi session print !!add_exl Comments for fortran unit
Directory with sources is /u1/ntausnev/PERL_vi for halem or
/home0/ntausnev/PERL_vi for Daley
//////////////////////////////////////////////////////////////////

checkout some files from some directory to current:
cvs -d /u1/ntausnev/CVS_ROOT checkout  -d . MAKEFILES
cvs -d /u1/ntausnev/CVS_ROOT checkout  -d . MAKEFILES/00ReadMe

//////////////////////////////////////////////////////////////////
Post Script file
gs namePostCriptFile.ps
//////////////////////////////////////////////////////////////////
Jan 13 2005
Delete 5 lines from head and 7 from the end:
perl -ne'BEGIN{$s=shift;$s+=$b=shift}print$b[$.%$b]if$.>$s;$b[$.% $b]=$_' 5 7 fileMame
//////////////////////////////////////////////////////////////////
12/21/04
How can I pull out lines between two patterns that are themselves on different
               lines?

perl -ne 'print if /START/ .. /END/' file1 file2 ...

Example: perl -ne 'print if /0.199150/../0.200050/' file

                  If you wanted text and not lines, you would use

perl -0777 -ne 'print "$1\n" while /START(.*?)END/gs' file1 file2 ...

                  But if you want nested occurrences of "START" through "END", you'll run
                  up against the problem described in the question in this section on
                  matching balanced text.

                  Here's another example of using "..":

                      while (<>) {
                          $in_header =   1  .. /^$/;
                          $in_body   = /^$/ .. eof();
                          # now choose between them
                      } continue {
                          reset if eof();         # fix $.
                      }

               -
//////////////////////////////////////////////////////////////////
09/30/04
Assume that the default module is fortran/551J, your script can look
like

        module switch fortran/551J fortran/551
        f90 -c atm.o atm.f90

        module switch fortran/551 fortran/551J
        f90 -c ocean.o ocean.f90
        f90 -c coupler.o coupler.f90

//////////////////////////////////////////////////////////////////
09/20/04
Kill character for shell
stty erase ^H
stty erase backspase (shift <- )
//////////////////////////////////////////////////////////////////
# print section of file between two regular expression (inclusive)
sed -n '/SUBROUTINE HANDLE_ERR/,/END SUBROUTINE HANDLE_ERR/p' z_readCDF.f90
//////////////////////////////////////////////////////////////////
#!/usr/local/bin/perl
#
#USAGE => delDuplicateLines.pl file_in file_out
#
#Description:
#  remove duplicate lines from input file

perl -ne 'print if 1 == ++$seen{$_}' file

To remove non-consecutive duplicate lines, use awk:

awk '!x[$0]++' FILE

//////////////////////////////////////////////////////////////////
06/23
DIRAC transfer data:
sftp -oport=2222 dirac

here is script to transfer data:
cat /giss2/giss/exec/to_utx

//////////////////////////////////////////////////////////////////
06/21/04
nco operators are at
ntausnev@halem2: /usr/ulocal/bin> ls nc*
ncap      ncbo      ncdump    ncecat    ncgen     ncra      ncrename
ncatted   ncdiff    ncea      ncflint   ncks      ncrcat    ncwa
ntausnev@halem2: /usr/ulocal/bin>
//////////////////////////////////////////////////////////////////
04/02/04
Directory /giss/ntausnev/ATMOS_GRID_M4 has the code for preparation
xgrid for 3x3 MOM4 (test4) and 4x5 GISS atmosphere and land grids.
All was done on SGI.
//////////////////////////////////////////////////////////////////
03/30/04
mom4p0b is on Ra:
NICK@RA: /raid10/nick> ls mom*
mom4p0b.tar

mom4p0b:
CVS/     bin/     doc/     exp/     readme   src/
NICK@RA: /raid10/nick>
//////////////////////////////////////////////////////////////////
03/04/04
script clean *.lis files was written. See at
   /u1/ntausnev/MY_UTIL/cleanLisFile.ksh

cut -c10- $nameFile | sed '/^$/d' | grep -v "Source Listing       " | \
		      sed '/^OPTIONS BEING USED/q' | more
//////////////////////////////////////////////////////////////////
02/10/04
New compiler on COMPAQ
module unload fortran
f90 -version
module list
module load fortran/551H
f90 -version
//////////////////////////////////////////////////////////////////

> I need to write a script that will remove files older than 7 days.  I
> am leaning towards the find...exec...command but don't know how the
> whole script should be written.
> Thanks for any ideas!!
> Mike  Newbie Admin

The man page for find on most systems gives plenty of examples.

find /somedir -mtime +7 -type f -exec rm -f {} \;

Check the man page to see if you want to use ctime, mtime or atime
//////////////////////////////////////////////////////////////////
01/05/04
To insert a line after match (SED)
/REGEXP/{x;s/^/line to insert/;x;G;}

To insert a line before match (SED)
/REGEXP/{x;s/^/line to insert/;G;}
//////////////////////////////////////////////////////////////////
12/19/03
Add time attribute - calendar
/usr/ulocal/nco-2.8.4/bin/ncatted -a calendar_type,Time,c,c,NOLEAP z_attr.nc
/usr/ulocal/nco-2.8.4/bin/ncatted -a calendar,Time,c,c,NOLEAP z_attr.nc
Check your dataset to make sure calendar attribute exists
Use a ncatted command such as:
 ncatted -a calendar,time_axis_name,c,c,"julian" foo.nc


Add atribute coordinates for field DataH_xyt:
ncatted -a coordinates,DataH_xyt,a,c,"lon lat" zGissHyc.nc zz.nc

ncatted -a cartesian_axis,lon,c,c,"X" z_xyzt.nc
ncatted -a cartesian_axis,lat,c,c,"Y" z_xyzt.nc
ncatted -a cartesian_axis,level,c,c,"Z" z_xyzt.nc
ncatted -a cartesian_axis,time,c,c,"T" z_xyzt.nc

If the "calendar" attribute does not exist,
Check your dataset to make
sure calendar attribute exists " Use a ncatted command such as:
ncatted -a calendar,time_axis_name,c,c,"NOLEAP" foo.nc

//////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////

11/30/03
Find and delete files exactly created 18 days ago:
find /u1/ntausnev -mtime 18 -name "*"  -print | more
find /u1/ntausnev -mtime 18 -name "*"  -exec rm -f {} \;

07/22/03
Delete files start with - ( a dash)
rm ./-

01/15/03
Creation CVS repository:

cvs -d /u1/ntausnev/CPL_CVS init
export CVSROOT=/u1/ntausnev/CPL_CVS

# GO at work directory:
cd /u1/ntausnev/FREE_SRF/modelE/ocean_gfdl/EntTSI/CPL_SRCS_CVS

# Import all files at new diectory CPL_SRCS at repository:
cvs -d /u1/ntausnev/CPL_CVS import -m "Imported sources" CPL_SRCS nick start

# Get version directory (CPL_CREATE_DIRS_GFDL) under
# new name (/u1/ntausnev/ZZZ) from repository (/u1/ntausnev/CPL_CVS)
cvs -d /u1/ntausnev/CPL_CVS checkout -d /u1/ntausnev/ZZZ CPL_CREATE_DIRS_GFDL

SO, created repository with
ntausnev@halem2: /u1/ntausnev/CPL_CVS> ls
CPL_CREATE_DIRS_GFDL  CPL_SCRIPTS           CPL_SRCS              CVSROOT
ntausnev@halem2: /u1/ntausnev/CPL_CVS>
ntausnev@halem2: /u1/ntausnev/CPL_CVS> date
Wed Jan 15 10:41:09 EST 2003
ntausnev@halem2: /u1/ntausnev/CPL_CVS>
Enjoy !

# Commit your changes to the repository:
cvs commit -m "The same time steps: dtts=dtuv=3600. and segtim=0.125"


-----------------------------------------------------------------
-----------------------------------------------------------------
-----------------------------------------------------------------
-----------------------------------------------------------------
-----------------------------------------------------------------
-----------------------------------------------------------------
-----------------------------------------------------------------
-----------------------------------------------------------------
-----------------------------------------------------------------
-----------------------------------------------------------------
-----------------------------------------------------------------
-----------------------------------------------------------------
-----------------------------------------------------------------
-----------------------------------------------------------------
-----------------------------------------------------------------
-----------------------------------------------------------------
-----------------------------------------------------------------
-----------------------------------------------------------------
03/08/03
Change password use next command:

passwd

-----------------------------------------------------------------
01/07/03
PRINT on pub2duplex text file 132 colums:
/usr/people/nick/Pub2/LPRT2 nameFile.txt

-----------------------------------------------------------------
12/09/02
For debuging csh script try to use -v -x options
-----------------------------------------------------------------
10/16/02
Put data for ftp in GISS

ftp ftp.giss.nasa.gov
anonymous
ntausnev@giss.nasa.gov
cd outgoing                || cd /incoming
put <file>

-----------------------------------------------------------------
09/30/02
Copy data at unitree:
ftp dirac
cd /u3/larissa/nick
binary
prompt
mput *
quit


-----------------------------------------------------------------
at COMMAND:
at -l
1031876880.a+5571       Fri Sep 13 00:28:00 2002

at -r 1031866200.a+5571    ===> remove a job from queue

at -f scriptfile 6 am Monday
at -f scriptfile 6 am today
at -f scriptfile 6 am tomorrow



at 1 pm today
echo "Send message" | mail you
CTRL-D

-----------------------------------------------------------------
09/05/02
Debug code for f90:
set FORTRAN_OPT_MOM = "-woff1670 -DEBUG:conform_check=YES:subscript_check=ON:trap_uninitialized=ON:v erbose_runtime=ON -g"

-----------------------------------------------------------------
Delete many files except ONE:
rm res*00203[0-1].[0-1]!(3).01.dta
-----------------------------------------------------------------
Read .pdf file:
acroread file.pdf

Print pdf file from NETSCAPE (command to print):
lpr -Ppub2duplex

cups-lpr -Ppub2duplex fname.pdf

Read *.gif:
xv file.gif
------------------------------------------------------------------
07/26/02
Pusk interactivly for very long time:

nohup /giss/ntausnev/HFLX/PROG_HFLX/06zapusk_mom_giss  1>list 2>list &
nohup test.sh > MyOutput.log 2>&1 </dev/null &
------------------------------------------------------------------

INCLUDE files and preprocessing

f90 -ftpp -macro_expand -Duse_libSMA -Dtest_mpp mpp.F90  \
	   -I/raid7/nick/MPP_TEST -lsma -lmpi -lexc
------------------------------------------------------------------

COMPUTER at GSFC log in:
ssh -X daley.gsfc.nasa.gov -l ron

------------------------------------------------------------------

FROM GSFC to RA

scp -p ntausnev@daley.gsfc.nasa.gov:/giss/ntausnev/file .

------------------------------------------------------------------

TO  GSFC from RA:

scp -p file_out ntausnev@daley.gsfc.nasa.gov:/giss/ntausnev/file_in
------------------------------------------------------------------

If you want to check the tabs in your file, issue the command

cat -v -t -e file

where the -v and -t options cause all tabs to appear as ^I,
and the -e option places a dollar sign at the end of each line.
------------------------------------------------------------------

Print copies of online man pages
man xxx | col -b | lpr

Again, you use the -t option, but this time you send the output to a
PostScript file named for the ls command. If that process completes
successfully, you convert the PostScript file to a PDF using the ps2pdf
command, and then after that finishes correctly, you delete the original
PostScript file because it's no longer needed.

$ man -t ls > ls.ps && ps2pdf ls.ps && rm ls.ps

------------------------------------------------------------------

SUBSTITUTING STRINGS IN MANY FILES

perl -pi.bak -e 's/OLDSTRING/NEWSTRING/ig' FILELIST

OLDSTRING the string of caracters to be replaced with NEWSTRING.
If the string contains any non-alphanumeric characters, use \.

The original files are saved as backup versions with a suffixed
.bak. If you do not want a backup (or want a different backup
suffix), change the .bak part of the procedure accordingly.

------------------------------------------------------------------
CVS updates module E, in directory model:

cvs update -A

cvs commit <file.f>

Add directory to the repository:

Stay at the directory with files:

cvs -d absPathRepository import -m "Text" nameDirInRepository nick start:

cvs -d /usr/people/nick/CVS_CPL import -m "mytext" Name_new_dir nick start
cvs -d /usr/people/nick/CVS_RLID import -m "Imported sources" SOURCES nick start


CHECKOUT from repository some directory with new name:
cvs -d absPathRepository checkout -d newNameDir dirInRepository

cvs -d /usr/people/nick/CVS_RLID checkout -d XXX SOURCES

EXAMPLE from Daley (from scratch):
cvs -d /giss/ntausnev/CVS_ROOT init   # Create repository
cd  NETCDF_MY                         # go in the necessary dir
Delete files that you think not need for CVS
cvs -d /giss/ntausnev/CVS_ROOT import -m "Imported sources" NETCDF_MY nick start #
cd ..
cvs -d /giss/ntausnev/CVS_ROOT checkout -d NETCDF_MYSTUFF NETCDF_MY # New directory is
								    # ready for CVS

------------------------------------------------------------------

Command to save a copy of a man page with the formatting
characters stripped out:

man command_name | col | ul -t dumb > filename

------------------------------------------------------------------
Find files with search criteria and acions:
find . -name "FTN*" -print

find . -name "*cdf*.F*" -exec ls -lat {} \;
------------------------------------------------------------------
It's installed in "/usr/local/netcdf-3.5.0"

Generate fortran program that reads NETCDF file:
f77 /usr/people/nick/NETCDF_UTIL/gennet.f \
    -I/usr/local/netcdf-3.4/include \
    -L/raid3/nick/NETCDF/netcdf-3.4/lib -lnetcdf
------------------------------------------------------------------
f90 file.f90 \
-I/raid7/nick/NETCDF_3_5_0/srcn32/f90 \
-L/raid7/nick/NETCDF_3_5_0/srcn32/libsrc -lnetcdf
------------------------------------------------------------------
How to deal with netcdf files?
Mar 28, 2017

This page is organised as follows:

Read metadata and quickly visualise netcdf files
Modify netcdf files using the NCO operators
Using cdo operators
Read/Modify/Create netcdf files in fortran90
Read/Modify/Create netcdf files in Matlab
Read/Modify/Create netcdf files in Python
Read metadata and quickly visualise netcdf files

To list the metadata of a netcdf file (dimensions, variable names, attributes) :

ncdump -h file.nc
To list the metadata and the values of variable var1 :

ncdump -v var1 file.nc | more
To have a quick look at the fields (i.e. the variables) in the netcdf file, use ncview:

ncview file.nc &
Ferret is also a convenient software to have a quick look at netcdf files, e.g. :

ferret
  yes? use "/home/bob/DATA/bathy_meter.nc"
  yes? show data
  yes? shade BATHYMETRY
  yes? plot BATHYMETRY[i=200]
  yes? plot/over BATHYMETRY[i=215]
  yes? quit
See Ferret documentation here for more complex plots and diagnostics.

Modify netcdf files using the NCO operators

NCO tools consist of several powerful commands to read/modify/create netcdf files. The full documentation can be found [here]. Some simple basic command lines are shown here as an example.

To rename variable var1 as ÃƒÂ¢Ã‚Â€Ã‚ÂœnewvarÃƒÂ¢Ã‚Â€Ã‚Â or dimension x as ÃƒÂ¢Ã‚Â€Ã‚ÂœlonÃƒÂ¢Ã‚Â€Ã‚Â :

ncrename -O -v var1,newvar filein.nc fileout.nc
ncrename -O -d x,lon filein.nc fileout.nc
To crop a netcdf file, i.e. to reduce the domain size (with option -F indices start from 1):

ncks -F -d time,1,10 filein.nc fileout.nc
ncks -F -d x,92,111 filein.nc fileout.nc
Similarly, if you have a well written netcdf file (with appropriate attributes) and a lon-lat grid, you may be able to use (donÃƒÂ¢Ã‚Â€Ã‚Â™t forget the dots in the numbers):

ncks -d lat,-30.0,30.0 filein.nc fileout.nc
To only keep variables var1 and var2 in a netcdf file (option -O is to overwritte):

ncks -O -v var1,var2 filein.nc fileout.nc
To remove variables var1 and var2 from a netcdf file:

ncks -O -x -v var1,var2 filein.nc fileout.nc
To merge two files of same dimension (name and size), e.g. file1.nc containing the variable var(x,y) and file2.nc containing the variables nav_lon(x,y), nav_lat(x,y) and Bathymetry(x,y), you can do as follows:

ncks -A file1.nc file2.nc
The variable var(x,y) will then be included into file2.nc

To concatenate files with the same variables and consecutive time steps (e.g. there is one file per month [whatever the output frequency within this file] and you want a file containing the JJAS months):

ncrcat JUN1979.nc JUL1979.nc AUG1979.nc SEP1979.nc JJAS_1979.nc
To calculate time-averages, e.g. to calculate a monthly mean from a file containing daily outputs:

ncra -F -d time,1,31 file_January_daily.nc file_January_monthly.nc
This can also be used to calculate mean Jan/Feb/March/ÃƒÂ¢Ã‚Â€Ã‚Â¦ over a multi-year file:

ncra -F -d time,1,1872,12 tos_monthly_1850-2005.nc tos_mean_JAN.nc
ncra -F -d time,2,1872,12 tos_monthly_1850-2005.nc tos_mean_FEB.nc
ncra -F -d time,3,1872,12 tos_monthly_1850-2005.nc tos_mean_MAR.nc
To remove a degenerated dimension (e.g. z):

ncwa -F -a z,1 filein.nc fileout.nc
Here are a few examples showing how to modify netcdf attributes (see NCO user guide for further information). To delete attribute ÃƒÂ¢Ã‚Â€Ã‚Âœstandard_nameÃƒÂ¢Ã‚Â€Ã‚Â for variable ÃƒÂ¢Ã‚Â€Ã‚Âœvar1ÃƒÂ¢Ã‚Â€Ã‚Â:

ncatted -a standard_name,var1,d,, filein.nc fileout.nc
To modify existing attribute ÃƒÂ¢Ã‚Â€Ã‚Âœlong_nameÃƒÂ¢Ã‚Â€Ã‚Â of character type for variable var1:

ncatted -a long_name,var1,m,c,'temperature' filein.nc fileout.nc
To create non-existing attribute ÃƒÂ¢Ã‚Â€Ã‚ÂœunitsÃƒÂ¢Ã‚Â€Ã‚Â of character type for variable var1:

ncatted -a units,var1,c,c,'K' filein.nc fileout.nc
Finally, a very powerful command is ncap2. Again, there is a large number of possibilities, see NCO user guide for further information. A few examples are given here: To calculate new variable called KE from existing uu and vv variables:

ncap2 -F -s "KE=0.5*(uu*uu+vv*vv)" file_in.nc file_out.nc
To create a land mask variable (sftlf) based on SST (tos) values :

ncap2 -F -s "sftlf=tos(1,:,:)*0.0 ; \\
sftlf = sftlf.delete_miss() ; \\
sftlf(:,:) = 100.0 ; \\
where( tos(1,:,:) > 260.0 || tos(1,:,:) < 310.0 ) sftlf=0.0" \\
filein.nc fileout.nc
To use a loop to fill existing variable X from index 1 to index 482:

ncap2 -F -s \\
"idx=1 ; while(idx<482){X(idx) = 20.0+0.75*idx; idx++;}" \\
filein.nc fileout.nc

https://www.dkrz.de/up/services/analysis/data-processing/tools/cdo-examples
Using cdo operators
cdo infon 1992-2014_cal.vsurf_h_2x2.nc
cdo sinfon 1992-2014_cal.vsurf_h_2x2.nc
cdo ninfo 1992-2014_cal.vsurf_h_2x2.nc
cdo nmon 1992-2014_cal.vsurf_h_2x2.nc
cdo ntime 1992-2014_cal.vsurf_h_2x2.nc
cdo showmon 1992-2014_cal.vsurf_h_2x2.nc
cdo showdate  1992-2014_cal.vsurf_h_2x2.nc

Change the reference time units or add a missing time dimension
Use the settaxis operator to do this for you, e.g. set the
reference time units to "2000-01-01,12:00:00,1day":

cdo -r -f nc -settaxis,2000-01-01,12:00:00,1day infile outfile

Select a time range
E.g. all variables in the range 1 to 12 timesteps:
cdo -seltimestep,1/12 infile outfile

cdo -seltimestep,126/134 1992-2014_cal.vsurf_h_2x2.nc z.nc



Many things (running means, EOF, conversions, etc) can now be done using
the cdo operators. For a list of available operators and options, see: this PDF

A few very simple examples are shown below.

To create a variable from the sum (var_sum) of two existing variables (var1 & var2) :

cdo expr,'var_sum=var1+var2' file_in.nc file_out.nc
To check whether two netcdf files are identical, or to find where differences are :

cdo diffn file_in.nc file_out.nc
To convert grib to netcdf :

cdo -f nc copy file_in.grib file_out.nc
As variable names are not stored in grib files, you may need to contact the institute that built the grib file to identify variables (e.g. check ungrib/Variable_Tables for WRF/WPS files).

Read/Modify/Create netcdf files in fortran90

It can be convenient to read netcdf files in your fortran scripts, or to create fortran scripts to treat large netcdf files. For this, you can use the netcdf-fortran library.

Here is an example of very basic fortran program that can be used to read a netcdf file, create or modify a variable and create a new netcdf file that is similar to the first one: example.f90.

A way to compile and execute it (e.g. with the ifort compiler) is :

NC_INC="-I /apps/netcdf/4.2.1.1/include"  ## to adapt
NC_LIB="-L /apps/netcdf/4.2.1.1/lib -lnetcdf -lnetcdff" ## to adapt
ifort -c $NC_INC example.f90
ifort -o run_example example.o $NC_LIB
./run_example
NB1: to find the netcdf path, you can do:

nc-config --libs
nc-configs --includedir
NB2: if you want to install the libraries yourself, check this page.
------------------------------------------------------------------
Dark theme:
I use both, like them equally but differently. For a couple/few years now.
Dark Reader for regular browsing or lots of surfing, jumping around
links/URLs, I think it's snappier on loading pages.
Dark Background and Light Text - when I do more heavy reading.
But I do have two colors changed for comfort. Foreground #b4a079
and background #1c1c1c. The rest is default.


------------------------------------------------------------------
------------------------------------------------------------------
------------------------------------------------------------------
------------------------------------------------------------------
